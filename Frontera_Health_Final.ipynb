{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f72d420843b4481ab3f1b7a9f0348b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7f2ac0436a040e3bf1b859cddd05a49",
              "IPY_MODEL_7432328be7684077838412c4e3eba07f",
              "IPY_MODEL_c43edefce9b848f5b985eb3d069b91d7"
            ],
            "layout": "IPY_MODEL_c606a0f1ffad46219f4d23caed13b686"
          }
        },
        "f7f2ac0436a040e3bf1b859cddd05a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082d3205a55843e083a2361e3af37ae8",
            "placeholder": "​",
            "style": "IPY_MODEL_407e10bfc969477390fec0b31b2638fc",
            "value": "config.json: 100%"
          }
        },
        "7432328be7684077838412c4e3eba07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be61a06275e84b01b123bab8b47ee460",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e73a2f29c62d41cf9fcbe2987ad3347b",
            "value": 571
          }
        },
        "c43edefce9b848f5b985eb3d069b91d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46018c4dd208463890d38386d327bd74",
            "placeholder": "​",
            "style": "IPY_MODEL_bed2529f97364f23af491f1bda854779",
            "value": " 571/571 [00:00&lt;00:00, 37.7kB/s]"
          }
        },
        "c606a0f1ffad46219f4d23caed13b686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082d3205a55843e083a2361e3af37ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407e10bfc969477390fec0b31b2638fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be61a06275e84b01b123bab8b47ee460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73a2f29c62d41cf9fcbe2987ad3347b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46018c4dd208463890d38386d327bd74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed2529f97364f23af491f1bda854779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2c65c7838c541248f42654944472659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d48aa0e1ed094c81b619e611c932e7a1",
              "IPY_MODEL_9ceb95cb60054427857dd374bda2a76e",
              "IPY_MODEL_2dd0306f16b14964addf90cc109f5f19"
            ],
            "layout": "IPY_MODEL_137155e08d694ad5849e09ceafe96d64"
          }
        },
        "d48aa0e1ed094c81b619e611c932e7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1913668287cb4ebba665f9763d703cc9",
            "placeholder": "​",
            "style": "IPY_MODEL_5e5a897795584133bcaaff1ce59468f8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9ceb95cb60054427857dd374bda2a76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a1f69c718384d81a8f322c8b0893484",
            "max": 1467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a39ff8fcfa24f7aaa339955b0485c1e",
            "value": 1467
          }
        },
        "2dd0306f16b14964addf90cc109f5f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19413b87ac054fd3b3124f02da45a93c",
            "placeholder": "​",
            "style": "IPY_MODEL_12e11d8c08c345dc85a37ef2d2cf5dd3",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 94.8kB/s]"
          }
        },
        "137155e08d694ad5849e09ceafe96d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1913668287cb4ebba665f9763d703cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5a897795584133bcaaff1ce59468f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a1f69c718384d81a8f322c8b0893484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a39ff8fcfa24f7aaa339955b0485c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19413b87ac054fd3b3124f02da45a93c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e11d8c08c345dc85a37ef2d2cf5dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d6fa71a821242cba6b343e51b18cdd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bc097ca4d644a2590e05eef72c8952c",
              "IPY_MODEL_6f0c8c72e0024431bd61f6b2679aba16",
              "IPY_MODEL_ebb99232897a45a0ad6f9294ecb17cc6"
            ],
            "layout": "IPY_MODEL_8683eecc2b154f348979e0dbb53dffb8"
          }
        },
        "2bc097ca4d644a2590e05eef72c8952c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f56ab5e30b5c44c09dbadb851653d90c",
            "placeholder": "​",
            "style": "IPY_MODEL_b456913f94904166b953a1e779e0f133",
            "value": "tokenizer.model: 100%"
          }
        },
        "6f0c8c72e0024431bd61f6b2679aba16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f6e57e29784edfbe2b3c031621d300",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55f9ef4f643441a9b03befdb71daeb43",
            "value": 493443
          }
        },
        "ebb99232897a45a0ad6f9294ecb17cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a37ca6bd7f804e3e91284481392d2e7e",
            "placeholder": "​",
            "style": "IPY_MODEL_4001cfe9ba6744d686aa3da48d7fb68d",
            "value": " 493k/493k [00:00&lt;00:00, 7.88MB/s]"
          }
        },
        "8683eecc2b154f348979e0dbb53dffb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56ab5e30b5c44c09dbadb851653d90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b456913f94904166b953a1e779e0f133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98f6e57e29784edfbe2b3c031621d300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55f9ef4f643441a9b03befdb71daeb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a37ca6bd7f804e3e91284481392d2e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4001cfe9ba6744d686aa3da48d7fb68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1da1ecbe10904e4fb001580ad17812f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18fdbcaeb17d4407aa82b42d8abb26a0",
              "IPY_MODEL_2cd8f345bceb43918997232d7ea0291f",
              "IPY_MODEL_7370b2a927324f3ab9f479b00fa81e0c"
            ],
            "layout": "IPY_MODEL_c272cec7bcfc4787b78760d9a64332c6"
          }
        },
        "18fdbcaeb17d4407aa82b42d8abb26a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ece5d27dc004007bad6947fd6cdf86d",
            "placeholder": "​",
            "style": "IPY_MODEL_8a33a8d822724627a81080a768253d2f",
            "value": "tokenizer.json: 100%"
          }
        },
        "2cd8f345bceb43918997232d7ea0291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_833f4e9b91214a68b12882394ebf1e55",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99fcdc23031d461f851748e85e546a82",
            "value": 1795303
          }
        },
        "7370b2a927324f3ab9f479b00fa81e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c753742ad4b47449543dadd80269caf",
            "placeholder": "​",
            "style": "IPY_MODEL_cb434513b4404605a7bd863c7dc814ef",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 22.7MB/s]"
          }
        },
        "c272cec7bcfc4787b78760d9a64332c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ece5d27dc004007bad6947fd6cdf86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a33a8d822724627a81080a768253d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "833f4e9b91214a68b12882394ebf1e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99fcdc23031d461f851748e85e546a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c753742ad4b47449543dadd80269caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb434513b4404605a7bd863c7dc814ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fef68f7be5149668f5f4be5f264ea74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74ed5f1141334155ac1bb027de4783c1",
              "IPY_MODEL_2f08de7486a245bb9af143ae00f43087",
              "IPY_MODEL_a1c900ac50a14299a36ca6a5266852a2"
            ],
            "layout": "IPY_MODEL_3bbc9d47164c4a43a2c1c1e2d58088cb"
          }
        },
        "74ed5f1141334155ac1bb027de4783c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc82ab7976a042d89a05bba8512f548e",
            "placeholder": "​",
            "style": "IPY_MODEL_80cae7fb6b824041ab01e45068ed88a0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "2f08de7486a245bb9af143ae00f43087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc364b2650e5413f9046c883215d0774",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_526fde03ed6f485295c789ec28c7cbbd",
            "value": 72
          }
        },
        "a1c900ac50a14299a36ca6a5266852a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf908c05c934ce3bcc7e3b4ac33626a",
            "placeholder": "​",
            "style": "IPY_MODEL_300a01f64a394c6f84242e5f01a4b933",
            "value": " 72.0/72.0 [00:00&lt;00:00, 4.80kB/s]"
          }
        },
        "3bbc9d47164c4a43a2c1c1e2d58088cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc82ab7976a042d89a05bba8512f548e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80cae7fb6b824041ab01e45068ed88a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc364b2650e5413f9046c883215d0774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526fde03ed6f485295c789ec28c7cbbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cf908c05c934ce3bcc7e3b4ac33626a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300a01f64a394c6f84242e5f01a4b933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cedb65c1990d492f898154c8ad555c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d508001597d4f26932190a2739778d1",
              "IPY_MODEL_5943a8464d5d4a2091f95265c056ea24",
              "IPY_MODEL_6d88d6ab050245e7ae451f4396e8f57c"
            ],
            "layout": "IPY_MODEL_d86e07aa007747f9b62485e1ee4affa0"
          }
        },
        "6d508001597d4f26932190a2739778d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a53158ca0e4df9b57dee366cdb4eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_4bdd04878c114d2c813ff02490b4322c",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "5943a8464d5d4a2091f95265c056ea24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_341f43d470004d8781f054657fdf4358",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_382341b6b10d40cb95bfb01802df476b",
            "value": 25125
          }
        },
        "6d88d6ab050245e7ae451f4396e8f57c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be4df8bb35745dbb1f398a8b9f080b8",
            "placeholder": "​",
            "style": "IPY_MODEL_067a441929524ffb80e7df7506aa76a8",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "d86e07aa007747f9b62485e1ee4affa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a53158ca0e4df9b57dee366cdb4eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdd04878c114d2c813ff02490b4322c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "341f43d470004d8781f054657fdf4358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382341b6b10d40cb95bfb01802df476b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4be4df8bb35745dbb1f398a8b9f080b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067a441929524ffb80e7df7506aa76a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf804067b95a4535b2a481f7e38d5f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d84771cc13c4bc9a60bc546bf333ff8",
              "IPY_MODEL_cd6e7c54a1994849ae8b86b8bf2b617f",
              "IPY_MODEL_7aa1e1044aee40c2a006304e65ed655d"
            ],
            "layout": "IPY_MODEL_a7100b861ebc47b78f174219d2c29e7d"
          }
        },
        "5d84771cc13c4bc9a60bc546bf333ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1053c1a4c67140ac82b84b0a85e91125",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ab6fcc2bea4bbbb9324aaac434ea48",
            "value": "Downloading shards: 100%"
          }
        },
        "cd6e7c54a1994849ae8b86b8bf2b617f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2abb97d89ab479c8aff5e4c1dd95a70",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5972abdb4a864a4ca4981ee9b9e21731",
            "value": 2
          }
        },
        "7aa1e1044aee40c2a006304e65ed655d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aeea2bfba72431eb77b9e5d1db3c286",
            "placeholder": "​",
            "style": "IPY_MODEL_8ce8307ec3c44398bbac55f7d1ac8962",
            "value": " 2/2 [02:23&lt;00:00, 67.38s/it]"
          }
        },
        "a7100b861ebc47b78f174219d2c29e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1053c1a4c67140ac82b84b0a85e91125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ab6fcc2bea4bbbb9324aaac434ea48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2abb97d89ab479c8aff5e4c1dd95a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5972abdb4a864a4ca4981ee9b9e21731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aeea2bfba72431eb77b9e5d1db3c286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ce8307ec3c44398bbac55f7d1ac8962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4aa25a96a1d4981a2d39fce8f35d932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6d0a2ba393341cca104bef06a328e96",
              "IPY_MODEL_f62160e67c6f4d4aa9821343d0f810be",
              "IPY_MODEL_9dcfbcdfac8347e097b0d436e13442e9"
            ],
            "layout": "IPY_MODEL_d6ff4ee49ee7474b9ec5fcf6e6393e99"
          }
        },
        "a6d0a2ba393341cca104bef06a328e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f8a67292b1d41acbb26572b8507bee7",
            "placeholder": "​",
            "style": "IPY_MODEL_75c8f1294b7443c3ad4cd526703fc866",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "f62160e67c6f4d4aa9821343d0f810be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f8c2ba51cb4e508ec5b6897fd287c4",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37644f753e5d44088876883c43288705",
            "value": 9942981696
          }
        },
        "9dcfbcdfac8347e097b0d436e13442e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd51f61cf15d4129a45661e21b929862",
            "placeholder": "​",
            "style": "IPY_MODEL_6a7be976cd814c8f80fea9d726d2eabb",
            "value": " 9.94G/9.94G [01:37&lt;00:00, 175MB/s]"
          }
        },
        "d6ff4ee49ee7474b9ec5fcf6e6393e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8a67292b1d41acbb26572b8507bee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c8f1294b7443c3ad4cd526703fc866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f8c2ba51cb4e508ec5b6897fd287c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37644f753e5d44088876883c43288705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd51f61cf15d4129a45661e21b929862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7be976cd814c8f80fea9d726d2eabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a75a86f878254832bbb1246a3dbe1198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_008398ed0b3b48bbb611543385472d92",
              "IPY_MODEL_1d17927b8e8a466fa67081c703d41f5b",
              "IPY_MODEL_8b52892881be4a51bf9556a66e909ca5"
            ],
            "layout": "IPY_MODEL_cd1105558ab943059e434dc14613c42b"
          }
        },
        "008398ed0b3b48bbb611543385472d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eead7c5c1b9a4875a5d9a6aac40a96f5",
            "placeholder": "​",
            "style": "IPY_MODEL_54d1efa6aa7b430aa56e272c6dd963fe",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "1d17927b8e8a466fa67081c703d41f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b81742db9546eb8eae67a7d5decb1a",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7629fb22ab9c407398e6f8eaf86d887e",
            "value": 4540516344
          }
        },
        "8b52892881be4a51bf9556a66e909ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d87098ddc024901b264a8696cbd7f15",
            "placeholder": "​",
            "style": "IPY_MODEL_c8ac1022e1404933a6f37ff2b1ce0a82",
            "value": " 4.54G/4.54G [00:45&lt;00:00, 152MB/s]"
          }
        },
        "cd1105558ab943059e434dc14613c42b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eead7c5c1b9a4875a5d9a6aac40a96f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d1efa6aa7b430aa56e272c6dd963fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b81742db9546eb8eae67a7d5decb1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7629fb22ab9c407398e6f8eaf86d887e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d87098ddc024901b264a8696cbd7f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8ac1022e1404933a6f37ff2b1ce0a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1245585c8e3d40bca47ef44fe0385a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e49498a60eb34bef8da4da9eba1f73c9",
              "IPY_MODEL_9eda97532ce1494088970c2256f929d8",
              "IPY_MODEL_ba19faf679de4e2b92d99a9dd9ac01c2"
            ],
            "layout": "IPY_MODEL_de0839d917e8448bbe1483d7fdf30fcb"
          }
        },
        "e49498a60eb34bef8da4da9eba1f73c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e9453d7f1244a29c48e6b0a7963859",
            "placeholder": "​",
            "style": "IPY_MODEL_c39f663b08444fee8f3567b6bc9d2161",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9eda97532ce1494088970c2256f929d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e76b2f6afa4c3a84316d3f13c99f5e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07164305df2a43feb4ec8656319363d3",
            "value": 2
          }
        },
        "ba19faf679de4e2b92d99a9dd9ac01c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59dbf79a40f54e998efbe2c2c2d34c31",
            "placeholder": "​",
            "style": "IPY_MODEL_f3cea159be16445c86163a6dec9c0b97",
            "value": " 2/2 [01:14&lt;00:00, 34.66s/it]"
          }
        },
        "de0839d917e8448bbe1483d7fdf30fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e9453d7f1244a29c48e6b0a7963859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39f663b08444fee8f3567b6bc9d2161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8e76b2f6afa4c3a84316d3f13c99f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07164305df2a43feb4ec8656319363d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59dbf79a40f54e998efbe2c2c2d34c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3cea159be16445c86163a6dec9c0b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1dffb68270f4fccb57b602f5539b2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26bf3fc5176d4319827ee203c3bfa9a2",
              "IPY_MODEL_28b4c209a9ba47eab0c882374a12247a",
              "IPY_MODEL_26a40c7d0c0e49c599d421b0083b03e9"
            ],
            "layout": "IPY_MODEL_8e4d9b1f9dc740f9a34376a27e67398c"
          }
        },
        "26bf3fc5176d4319827ee203c3bfa9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8c63a14cb7420489860147ca3d9d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_a57e53d3740746e889b9e81c1ce8b321",
            "value": "generation_config.json: 100%"
          }
        },
        "28b4c209a9ba47eab0c882374a12247a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c6834e7065e4f5bad74acb73d8fd555",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d84c56177e464d3e860532941de213e7",
            "value": 116
          }
        },
        "26a40c7d0c0e49c599d421b0083b03e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8423b54de87a48febc5ecf6b6b263b5b",
            "placeholder": "​",
            "style": "IPY_MODEL_0f74b80f7619454982a02e68f0cec0b1",
            "value": " 116/116 [00:00&lt;00:00, 6.40kB/s]"
          }
        },
        "8e4d9b1f9dc740f9a34376a27e67398c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8c63a14cb7420489860147ca3d9d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a57e53d3740746e889b9e81c1ce8b321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c6834e7065e4f5bad74acb73d8fd555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84c56177e464d3e860532941de213e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8423b54de87a48febc5ecf6b6b263b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f74b80f7619454982a02e68f0cec0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libraries"
      ],
      "metadata": {
        "id": "ZKtP3w6uAZgS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih7uNIP73lLW",
        "outputId": "a5ea942d-3e7d-4c1e-880d-f7c35b22d4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.1.15-py3-none-any.whl (814 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m814.5/814.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.41 (from langchain)\n",
            "  Downloading langchain_core-0.1.41-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.43-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting packaging>=19.1 (from build>=1.0.3->chromadb)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=34c810d0bdbb19a7963620e80537d44656448b26114e331e3c11a55cdcddc35d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, python-dotenv, PyPDF2, pulsar-client, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, marshmallow, jsonpatch, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, fastapi, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-community, langchain, chromadb\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed PyPDF2-3.0.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 fastapi-0.110.1 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.0.0 jsonpatch-1.33 jsonpointer-2.4 kubernetes-29.0.0 langchain-0.1.15 langchain-community-0.0.32 langchain-core-0.1.41 langchain-text-splitters-0.0.1 langsmith-0.1.43 marshmallow-3.21.1 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.17.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.0 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.37.2 typing-inspect-0.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2 chromadb langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HTYHzYZ3oqi",
        "outputId": "7f640b20-6ff4-4daf-af14-0da859eb4c1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.39.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate bitsandbytes sentencepiece tiktoken huggingface-hub hf-transfer huggingface_hub[\"cli\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJCaRRhu3rf2",
        "outputId": "30a83a28-cc03-4371-dce6-26b8f0663d8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Collecting hf-transfer\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.10.0)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface-hub)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface-hub)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface-hub) (3.0.43)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: pfzy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, InquirerPy, nvidia-cusolver-cu12, bitsandbytes, accelerate\n",
            "Successfully installed InquirerPy-0.3.4 accelerate-0.29.2 bitsandbytes-0.43.0 hf-transfer-0.1.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pfzy-0.3.4 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement logic to read pdf files (Used pypdf instead of langchain doc loader)"
      ],
      "metadata": {
        "id": "XWec5f6rAeaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import chromadb\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Function to convert PDF to text\n",
        "def pdf_to_text(file_path):\n",
        "    pdf_file = open(file_path, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "        text += pdf_reader.pages[page_num].extract_text()\n",
        "    pdf_file.close()\n",
        "    return text"
      ],
      "metadata": {
        "id": "EIf1EEpc3y-x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logic to clean returned text from PDFs"
      ],
      "metadata": {
        "id": "_swTsPIiAmoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zcT0dnj32SE",
        "outputId": "d05e2f35-9073-4796-e563-89f91407be43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "def clean_text(text):\n",
        "    # Lowercase conversion\n",
        "    text = text.lower()\n",
        "\n",
        "    # Regular expressions for cleaning:\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove emails\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # Remove citations\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric (except spaces)\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
        "\n",
        "    # Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Stopword removal (customize as needed)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "5580tW_n35Cu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split text and upload docs to chromadb vector database"
      ],
      "metadata": {
        "id": "AD35b5GlA03y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize text splitter and embeddings\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# Initialize Chroma DB client\n",
        "client = chromadb.PersistentClient(path=\"./db\")\n",
        "collection = client.create_collection(name=\"my_collection\")\n",
        "\n",
        "# Process each PDF in the ./input directory\n",
        "batch_size = 150\n",
        "for filename in os.listdir('./pdf_files'):\n",
        "    if filename.endswith('.pdf'):\n",
        "        # Convert PDF to text\n",
        "        text = pdf_to_text(os.path.join('./pdf_files', filename))\n",
        "\n",
        "        #clean given text\n",
        "        text = clean_text(text)\n",
        "\n",
        "        # Split text into chunks\n",
        "        chunks = text_splitter.split_text(text)\n",
        "\n",
        "        # Convert chunks to vector representations and store in Chroma DB\n",
        "        for i in range(0, len(chunks), batch_size):\n",
        "            batch_chunks = chunks[i:i+batch_size]\n",
        "            batch_documents = batch_chunks\n",
        "            batch_ids = [f\"{filename}_{i}\" for i in range(i, i+len(batch_chunks))]\n",
        "\n",
        "            collection.add(\n",
        "                documents=batch_documents,\n",
        "                ids=batch_ids\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adrpAtaN37dd",
        "outputId": "6cd410b6-3da3-4e0b-aa87-1d2c80afa567"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 72.5MiB/s]\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1cc6b for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1ce61 for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1d014 for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1d1ae for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1d33d for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1d4af for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1d699 for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1d85b for key /MediaBox\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x1db05 for key /MediaBox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig, GenerationConfig, TextStreamer"
      ],
      "metadata": {
        "id": "Xra3AmIG3-HR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Mistral text generation llm model"
      ],
      "metadata": {
        "id": "EPMNekTDA4_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
        "\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_name,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "f72d420843b4481ab3f1b7a9f0348b83",
            "f7f2ac0436a040e3bf1b859cddd05a49",
            "7432328be7684077838412c4e3eba07f",
            "c43edefce9b848f5b985eb3d069b91d7",
            "c606a0f1ffad46219f4d23caed13b686",
            "082d3205a55843e083a2361e3af37ae8",
            "407e10bfc969477390fec0b31b2638fc",
            "be61a06275e84b01b123bab8b47ee460",
            "e73a2f29c62d41cf9fcbe2987ad3347b",
            "46018c4dd208463890d38386d327bd74",
            "bed2529f97364f23af491f1bda854779",
            "d2c65c7838c541248f42654944472659",
            "d48aa0e1ed094c81b619e611c932e7a1",
            "9ceb95cb60054427857dd374bda2a76e",
            "2dd0306f16b14964addf90cc109f5f19",
            "137155e08d694ad5849e09ceafe96d64",
            "1913668287cb4ebba665f9763d703cc9",
            "5e5a897795584133bcaaff1ce59468f8",
            "6a1f69c718384d81a8f322c8b0893484",
            "8a39ff8fcfa24f7aaa339955b0485c1e",
            "19413b87ac054fd3b3124f02da45a93c",
            "12e11d8c08c345dc85a37ef2d2cf5dd3",
            "1d6fa71a821242cba6b343e51b18cdd5",
            "2bc097ca4d644a2590e05eef72c8952c",
            "6f0c8c72e0024431bd61f6b2679aba16",
            "ebb99232897a45a0ad6f9294ecb17cc6",
            "8683eecc2b154f348979e0dbb53dffb8",
            "f56ab5e30b5c44c09dbadb851653d90c",
            "b456913f94904166b953a1e779e0f133",
            "98f6e57e29784edfbe2b3c031621d300",
            "55f9ef4f643441a9b03befdb71daeb43",
            "a37ca6bd7f804e3e91284481392d2e7e",
            "4001cfe9ba6744d686aa3da48d7fb68d",
            "1da1ecbe10904e4fb001580ad17812f5",
            "18fdbcaeb17d4407aa82b42d8abb26a0",
            "2cd8f345bceb43918997232d7ea0291f",
            "7370b2a927324f3ab9f479b00fa81e0c",
            "c272cec7bcfc4787b78760d9a64332c6",
            "7ece5d27dc004007bad6947fd6cdf86d",
            "8a33a8d822724627a81080a768253d2f",
            "833f4e9b91214a68b12882394ebf1e55",
            "99fcdc23031d461f851748e85e546a82",
            "2c753742ad4b47449543dadd80269caf",
            "cb434513b4404605a7bd863c7dc814ef",
            "7fef68f7be5149668f5f4be5f264ea74",
            "74ed5f1141334155ac1bb027de4783c1",
            "2f08de7486a245bb9af143ae00f43087",
            "a1c900ac50a14299a36ca6a5266852a2",
            "3bbc9d47164c4a43a2c1c1e2d58088cb",
            "dc82ab7976a042d89a05bba8512f548e",
            "80cae7fb6b824041ab01e45068ed88a0",
            "cc364b2650e5413f9046c883215d0774",
            "526fde03ed6f485295c789ec28c7cbbd",
            "5cf908c05c934ce3bcc7e3b4ac33626a",
            "300a01f64a394c6f84242e5f01a4b933"
          ]
        },
        "id": "RPxaocdp4BLb",
        "outputId": "8e92d093-b842-43e8-8d24-0beb0685ce23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f72d420843b4481ab3f1b7a9f0348b83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2c65c7838c541248f42654944472659"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d6fa71a821242cba6b343e51b18cdd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1da1ecbe10904e4fb001580ad17812f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fef68f7be5149668f5f4be5f264ea74"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "use_nested_quant = False"
      ],
      "metadata": {
        "id": "DADJw1QL4DzU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "# Check GPU compatibility with bfloat16\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "Y79cTKTz4GEg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "cedb65c1990d492f898154c8ad555c9a",
            "6d508001597d4f26932190a2739778d1",
            "5943a8464d5d4a2091f95265c056ea24",
            "6d88d6ab050245e7ae451f4396e8f57c",
            "d86e07aa007747f9b62485e1ee4affa0",
            "09a53158ca0e4df9b57dee366cdb4eb5",
            "4bdd04878c114d2c813ff02490b4322c",
            "341f43d470004d8781f054657fdf4358",
            "382341b6b10d40cb95bfb01802df476b",
            "4be4df8bb35745dbb1f398a8b9f080b8",
            "067a441929524ffb80e7df7506aa76a8",
            "bf804067b95a4535b2a481f7e38d5f1f",
            "5d84771cc13c4bc9a60bc546bf333ff8",
            "cd6e7c54a1994849ae8b86b8bf2b617f",
            "7aa1e1044aee40c2a006304e65ed655d",
            "a7100b861ebc47b78f174219d2c29e7d",
            "1053c1a4c67140ac82b84b0a85e91125",
            "f6ab6fcc2bea4bbbb9324aaac434ea48",
            "b2abb97d89ab479c8aff5e4c1dd95a70",
            "5972abdb4a864a4ca4981ee9b9e21731",
            "5aeea2bfba72431eb77b9e5d1db3c286",
            "8ce8307ec3c44398bbac55f7d1ac8962",
            "e4aa25a96a1d4981a2d39fce8f35d932",
            "a6d0a2ba393341cca104bef06a328e96",
            "f62160e67c6f4d4aa9821343d0f810be",
            "9dcfbcdfac8347e097b0d436e13442e9",
            "d6ff4ee49ee7474b9ec5fcf6e6393e99",
            "8f8a67292b1d41acbb26572b8507bee7",
            "75c8f1294b7443c3ad4cd526703fc866",
            "f9f8c2ba51cb4e508ec5b6897fd287c4",
            "37644f753e5d44088876883c43288705",
            "fd51f61cf15d4129a45661e21b929862",
            "6a7be976cd814c8f80fea9d726d2eabb",
            "a75a86f878254832bbb1246a3dbe1198",
            "008398ed0b3b48bbb611543385472d92",
            "1d17927b8e8a466fa67081c703d41f5b",
            "8b52892881be4a51bf9556a66e909ca5",
            "cd1105558ab943059e434dc14613c42b",
            "eead7c5c1b9a4875a5d9a6aac40a96f5",
            "54d1efa6aa7b430aa56e272c6dd963fe",
            "11b81742db9546eb8eae67a7d5decb1a",
            "7629fb22ab9c407398e6f8eaf86d887e",
            "3d87098ddc024901b264a8696cbd7f15",
            "c8ac1022e1404933a6f37ff2b1ce0a82",
            "1245585c8e3d40bca47ef44fe0385a5f",
            "e49498a60eb34bef8da4da9eba1f73c9",
            "9eda97532ce1494088970c2256f929d8",
            "ba19faf679de4e2b92d99a9dd9ac01c2",
            "de0839d917e8448bbe1483d7fdf30fcb",
            "f7e9453d7f1244a29c48e6b0a7963859",
            "c39f663b08444fee8f3567b6bc9d2161",
            "f8e76b2f6afa4c3a84316d3f13c99f5e",
            "07164305df2a43feb4ec8656319363d3",
            "59dbf79a40f54e998efbe2c2c2d34c31",
            "f3cea159be16445c86163a6dec9c0b97",
            "e1dffb68270f4fccb57b602f5539b2e9",
            "26bf3fc5176d4319827ee203c3bfa9a2",
            "28b4c209a9ba47eab0c882374a12247a",
            "26a40c7d0c0e49c599d421b0083b03e9",
            "8e4d9b1f9dc740f9a34376a27e67398c",
            "bb8c63a14cb7420489860147ca3d9d1d",
            "a57e53d3740746e889b9e81c1ce8b321",
            "9c6834e7065e4f5bad74acb73d8fd555",
            "d84c56177e464d3e860532941de213e7",
            "8423b54de87a48febc5ecf6b6b263b5b",
            "0f74b80f7619454982a02e68f0cec0b1"
          ]
        },
        "id": "hhfaDFS84ImQ",
        "outputId": "6a0ea55e-a5d5-4504-960b-9a6310724c08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cedb65c1990d492f898154c8ad555c9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf804067b95a4535b2a481f7e38d5f1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4aa25a96a1d4981a2d39fce8f35d932"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a75a86f878254832bbb1246a3dbe1198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1245585c8e3d40bca47ef44fe0385a5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1dffb68270f4fccb57b602f5539b2e9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create required prompts for summarization and answering user queries."
      ],
      "metadata": {
        "id": "u7T2gwQOBAc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "text_generation_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=1000,\n",
        ")\n",
        "\n",
        "Summarize_prompt_template = \"\"\"\n",
        "### [INST]\n",
        "Instruction: Summarize the following text:\n",
        "\n",
        "{text}\n",
        "\n",
        "[/INST]\n",
        " \"\"\"\n",
        "\n",
        "result_prompt_template = \"\"\"\n",
        "### [INST]\n",
        "Instruction: Answer the question based on your\n",
        "research findings on Autism, Therapy, and Intervention. Here is context to help:\n",
        "\n",
        "{context}\n",
        "\n",
        "### QUESTION:\n",
        "{question}\n",
        "\n",
        "[/INST]\n",
        " \"\"\"\n",
        "\n",
        "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "# Create prompt from prompt template\n",
        "summarize_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=Summarize_prompt_template,\n",
        ")\n",
        "\n",
        "# Create prompt from prompt template\n",
        "result_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=result_prompt_template,\n",
        ")\n",
        "\n",
        "# Create llm chain\n",
        "llm_chain_summ = LLMChain(llm=mistral_llm, prompt=summarize_prompt)\n",
        "llm_chain_res = LLMChain(llm=mistral_llm, prompt=result_prompt)"
      ],
      "metadata": {
        "id": "6i5crMe24LV2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions"
      ],
      "metadata": {
        "id": "RNiTYMPtBHud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What are the variety of Multimodal and Multi-modular AI Approaches to Streamline Autism Diagnosis in Young Children?\",\n",
        "    \"What is Autism Spectrum Disorder, and how is it caused?\",\n",
        "    \"What is the cure of Autism Spectrum Disorder?\",\n",
        "    \"What are Stereotypical and maladaptive behaviors in Autism Spectrum, how are these detected and managed?\",\n",
        "    \"How relevant is eye contact and how it can be used to detect Autism?\",\n",
        "    \"How can cross country trials help in the development of Machine learning based Multimodal solutions?\",\n",
        "    \"How early infants cry can help in the early detection of Autism?\",\n",
        "    \"What are various methods to detect Atypical Pattern of Facial expression in Children?\",\n",
        "    \"What kind of facial expressions can be used to detect Autism Disorder in children?\",\n",
        "    \"What are methods to detect Autism from home videos?\",\n",
        "    \"What is Still-Face Paradigm in Early Screening for High-Risk Autism Spectrum Disorder?\",\n",
        "    \"What is West Syndrome?\",\n",
        "    \"What is the utility of Behavior and interaction imaging at 9 months of age predict autism/intellectual disability in high-risk infants with West syndrome?\"\n",
        "]"
      ],
      "metadata": {
        "id": "uFkbWhIo4O7Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logic to save results"
      ],
      "metadata": {
        "id": "ZxrmJWYqBLGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for q in questions:\n",
        "  question_dict = {}\n",
        "  context = collection.query(\n",
        "      query_texts=[q],\n",
        "      n_results=5\n",
        "  )['documents'][0]\n",
        "  summaries = []\n",
        "  for i in context:\n",
        "    summary = llm_chain_summ.invoke({\"text\":i})['text'].split(\"[/INST]\")[-1]\n",
        "    summaries.append(summary)\n",
        "  res = llm_chain_res.invoke({\"context\":summaries,\n",
        "                    \"question\": q})['text'].split(\"[/INST]\")[-1]\n",
        "  question_dict['Question'] = q\n",
        "  question_dict['Retrieved Context'] = context\n",
        "  question_dict['Summaries'] = summaries\n",
        "  question_dict['Result'] = res\n",
        "  results.append(question_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIlPsb374SS8",
        "outputId": "a2220236-ac60-48e6-9125-f10cdf5a563c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 678, in format\n",
            "    record.message = record.getMessage()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
            "    msg = msg % self.args\n",
            "TypeError: not all arguments converted during string formatting\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-16-ed676f7aa670>\", line 10, in <cell line: 2>\n",
            "    summary = llm_chain_summ.invoke({\"text\":i})['text'].split(\"[/INST]\")[-1]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 103, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 115, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 597, in generate_prompt\n",
            "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 767, in generate\n",
            "    output = self._generate_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 621, in _generate_helper\n",
            "    self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_pipeline.py\", line 267, in _generate\n",
            "    responses = self.pipeline(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\", line 240, in __call__\n",
            "    return super().__call__(text_inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
            "    logger.warning_once(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
            "    self.warning(*args, **kwargs)\n",
            "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
            "Arguments: (<class 'UserWarning'>,)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print results"
      ],
      "metadata": {
        "id": "LOmCSuK9BPiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx69tvHg8bf6",
        "outputId": "a7cb0a77-4e9a-4247-dc1c-1340bbf08d72"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Question': 'What are the variety of Multimodal and Multi-modular AI Approaches to Streamline Autism Diagnosis in Young Children?',\n",
              "  'Retrieved Context': ['1 scientific report 2020 105014 wwwnaturecomscientificreportsmultimodular ai approach streamline autism diagnosis young child halim abbas 1 ford garberson 1 stuart liumayo 1 eric glover1 dennis p wall 2 autism become pressing healthcare challenge instrument used aid diagnosis time labor expensive require trained clinician administer leading long wait time atrisk child present multimodular machine learningbased assessment autism comprising three complementary module unified outcome diagnosticgrade reliability 4minute parentreport questionnaire delivered via mobile app list key behavior identified 2minute semistructured home video child 2minute questionnaire presented clinician time clinical assessment demonstrate assessment reliability blinded multisite clinical study child 1872 month age n 375 united state outperforms baseline screener administered child 035 90 ci 026 043 auc 069 90 ci 058 081 specificity operating 90 sensitivity compared baseline screener evaluated child le 48 month',\n",
              "   'wei w control architecture robot assisted intervention child autism spectrum disorder j robot 2018 12 2018 17 bekele e crittendon ja swanson sarkar n warren ze pilot clinical application adaptive robotic system young child autism autism international journal research practice 185 598608 2014 18 huijnen cagj lexis ma jansen r de witte lp mapping robot therapy educational objective child autism spectrum disorder j autism dev disord 466 21002114 2016 19 arestibartolome n begonya gz technology support tool person autistic spectrum disorder systematic review int j environ re public health 118 77677802 2014 20 boucenna narzisi tilmont e muratori f pioggia g cohen mohamed c interactive technology autistic child review cogn comput 64 722740 2014 21 grynszpan patrice l wei perezdiaz f gal e innovative technologybased intervention autism spectrum disorder metaanalysis autism 184 346361 2014 22 rehg jm rozga abowd gd goodwin m behavioral imaging autism ieee pervasive comput 132 8487 4 2014 23',\n",
              "   'two previously published13 automated autism assessment module underlying cognoa14 software first module based brief questionnaire child presented directly parent without supervision second module based lightly trained analyst evaluating short video child within natural environment captured parent using mobile device also present new third module intended completed primary care setting pediatrician office clinic visit third module based upon questionnaire answered clinician examining child talking parent demonstrate three module fast easy 1cognoa inc palo alto ca usa 2departments pediatrics biomedical data science psychiatry behavioral science stanford university stanford ca usa email scientific report 2020 105014 wwwnaturecomscientificreports wwwnaturecomscientificreportsadminister typical screening instrument yet combined assessment accuracy shown work significantly higher may used aid diagnosis autism present approach selecting maximally predictive feature module parent clinician',\n",
              "   'press springer andoxford university press dawson sapiro carpenter hashemi campbell espinosa baker egger helped develop aspect technology used inthe study technology licensed daw son sapiro carpenter hashemi espinosa baker egger duke university bene tednanciallyreferences adrien j l faure perrot hameury l garreau b barthelemy c sauvage 1991 autism familyhome movie preliminary ndings journal autism developmental disorder 211 43 49 adrien j l lenoir p martineau j perrot hameury l larmande c sauvage 1993 blind rating earlysymptoms autism based upon family home movie jour nal american academy child adolescent psy chiatry 323 617 626 19930500000019 bal v h kim h fok lord c 2019 autism spec trum disorder symptom age 2 19 year implicationsfor diagnosing adolescent young adult autismresearch 121 89 99 baranek g 1999 autism infancy retrospective video analysis sensorymotor social behavior 9 12 month age journal autism developmental disorder 293 213 224 bieberich morgan b 2004 selfregulation',\n",
              "   'funding national institute health travel reimbursement andor honorarium society clinical child adolescent psychology help group dr ozonoff received research grant funding national institute health autism speaks travel reimbursement honorarium editorial activity autism speaks autism science foundation wiley book royalty guilford press american psychiatric press inc dr schwichtenberg received grant funding national institute health travel support autism speaks autism science foundation author report financial disclosure potential conflict interest abbreviation asd autism spectrum disorder virsa videoreferenced infant rating system autism reference alqabandi gorter jw rosenbaum p 2011 early autism detection ready routine screening pediatrics 1281 e211e217 pubmed 21669896 arguel jamet e 2009 using video static picture improve learning procedural content computer human behavior 25 354359 baio j wiggins l christensen dl maenner mj daniel j warren z kurziusspencer zahorodny w'],\n",
              "  'Summaries': [\"\\n \\nThe scientific report published in Nature Communications in 2020 presents a multimodal AI approach to streamline autism diagnosis in young children. The approach uses a machine learning-based assessment that comprises three complementary modules, with a unified outcome diagnostic grade reliability of 4 minutes. The assessment is delivered via a mobile app and includes a 2-minute parent report questionnaire and a 2-minute semistructured home video of the child. The study demonstrated the assessment's reliability through a blinded multisite clinical study involving 1872 children aged 18-24 months in the United States. The results showed that the AI-based assessment outperformed the baseline screener administered to children aged 3-5 years old, with an AUC of 0.69 (90% CI 0.58-0.81) and specificity and sensitivity comparable to the baseline screener.\",\n",
              "   '\\n \\nThe text discusses various studies and research related to the use of robots in assisted interventions for children with autism spectrum disorders. The authors explore different approaches, such as adaptive robotic systems, robot therapy, and technology-based interventions, and their potential benefits in improving educational objectives and clinical applications for individuals with autism. They also examine the role of interactive technology, behavioral imaging, and metaanalysis in enhancing these interventions. Overall, the text highlights the growing interest in using robots to support individuals with autism spectrum disorders and the need for further research to evaluate their effectiveness and potential drawbacks.',\n",
              "   \"\\n \\nCognoa is a software company that has developed an automated autism assessment module for use in primary care settings. The module consists of three parts: a brief questionnaire, a video evaluation by a lightly trained analyst, and a clinician examination. The software has been shown to have significantly higher accuracy than typical screening instruments, making it a useful tool for aiding in the diagnosis of autism. The most predictive feature of the module is the parent's response to the questionnaire, followed by the clinician's examination and the video evaluation. Cognoa is located in Palo Alto, California, USA, and has two departments: Pediatrics, Biomedical Data Science, Psychiatry, and Behavioral Science at Stanford University in Stanford, California, USA.\",\n",
              "   '\\n \\nThe text describes a research project that involved developing aspect technology to study autism. The project was led by Dawson Sapiro, Carpenter Hashemi, Campbell Espinosa, Baker Egger, and Duke University. The researchers referenced several studies, including one by Adrien J. L. Faure, Perrot Hameury, L. Garreau, and B. Barthelemy C. Sauvage (1991) on autism in families, and another by Bal V. H. Kim, H. Fok, Lord, and others (2019) on the symptoms of autism spectrum disorder in adolescents and young adults. The text also mentions a study by Baranek (1999) on sensory-motor, social behavior in infants, and a study by Bieberich and Morgan (2004) on self-regulation.',\n",
              "   '\\n \\nThe text describes various grants and funding opportunities for researchers in the field of autism and related disorders. Dr. Ozonoff received a research grant from the National Institute of Health, while Dr. Schwichtenberg received a grant from the Autism Science Foundation. Both researchers also received travel reimbursement and honorariums for their work. Additionally, there are mentions of an editorial activity grant from Autism Speaks and a book royalty from Wiley. The text also includes references to several studies on early autism detection, including one by Argel Jamet et al. (2009) that used video and static pictures to improve learning procedures for children with autism spectrum disorder (ASD).'],\n",
              "  'Result': '\\n \\nThere are several multimodal and multi-modular AI approaches to streamline autism diagnosis in young children. One such approach is presented in a scientific report published in Nature Communications in 2020, which uses a machine learning-based assessment that comprises three complementary modules, with a unified outcome diagnostic grade reliability of 4 minutes. The assessment is delivered via a mobile app and includes a 2-minute parent report questionnaire and a 2-minute semistructured home video of the child. This approach has been shown to be reliable through a blinded multisite clinical study involving 1872 children aged 18-24 months in the United States.\\n\\nAnother example of a multi-modular AI approach to autism diagnosis is Cognoa, a software company that has developed an automated autism assessment module for use in primary care settings. The module consists of three parts: a brief questionnaire, a video evaluation by a lightly trained analyst, and a clinician examination. The software has been shown to have significantly higher accuracy than typical screening instruments, making it a useful tool for aiding in the diagnosis of autism.\\n\\nIn addition to these approaches, there are also various studies and research related to the use of robots in assisted interventions for children with autism spectrum disorders. These interventions can take different forms, such as adaptive robotic systems, robot therapy, and technology-based interventions, and have the potential to improve educational objectives and clinical applications for individuals with autism. Interactive technology, behavioral imaging, and metaanalysis are also examined in enhancing these interventions.\\n\\nOverall, there is growing interest in using robots to support individuals with autism spectrum disorders, and further research is needed to evaluate their effectiveness and potential drawbacks.'},\n",
              " {'Question': 'What is Autism Spectrum Disorder, and how is it caused?',\n",
              "  'Retrieved Context': ['press springer andoxford university press dawson sapiro carpenter hashemi campbell espinosa baker egger helped develop aspect technology used inthe study technology licensed daw son sapiro carpenter hashemi espinosa baker egger duke university bene tednanciallyreferences adrien j l faure perrot hameury l garreau b barthelemy c sauvage 1991 autism familyhome movie preliminary ndings journal autism developmental disorder 211 43 49 adrien j l lenoir p martineau j perrot hameury l larmande c sauvage 1993 blind rating earlysymptoms autism based upon family home movie jour nal american academy child adolescent psy chiatry 323 617 626 19930500000019 bal v h kim h fok lord c 2019 autism spec trum disorder symptom age 2 19 year implicationsfor diagnosing adolescent young adult autismresearch 121 89 99 baranek g 1999 autism infancy retrospective video analysis sensorymotor social behavior 9 12 month age journal autism developmental disorder 293 213 224 bieberich morgan b 2004 selfregulation',\n",
              "   'pmc 2021 january 01 author manuscript author manuscript author manuscript author manuscriptwetherby brosnanmaddox peace v newton l 2008 validation infanttoddler checklist broadbrand screener autism spectrum disorder 9 24 month age autism 125 487511 pubmed 18805944 zwaigenbaum l bryson rogers robert w brian j szatmari p 2005 behavioral manifestation autism first year life international journal developmental neuroscience 2323 143152 pubmed 15749241 zwaigenbaum l bauman ml fein pierce k buie davis pa newschaffer c robin dl wetherby choueiri r kasari c stone wl yirmiya n estes hansen rl mcpartland jc natowicz mr carter granpeesheh mailloux z smithroley wagner 2015 early screening autism spectrum disorder recommendation practice research pediatrics 136suppl 1 s41s59 pubmed 26430169 young et al page 10 j child psychol psychiatry author manuscript available pmc 2021 january 01 author manuscript author manuscript author manuscript author manuscriptkey point 1 sign asd present first two year',\n",
              "   '058 081 specificity operating 90 sensitivity compared baseline screener evaluated child le 48 month age assessment outperforms accurate 018 90 ci 008 029 90 auc 030 90 ci 011 050 specificity operating 90 sensitivity idiopathic form autism spectrum disorder asd known biological cause may correspond multiple condition similar symptom incidence asd increased recent year impact 1 59 child according latest study 1 asd diagnosed clinical observation according standard criteria2 relating child social behavioral symptom autism said spectrum due varied severity symptom ranging relatively mild social impairment debilitating intellectual disability inability change routine severe sensory reaction 2 approximately 25503 autistic child nonverbal severe symptom notably diagnosis within first year life dramatically improves outlook child autism allows treatment key window developmental plasticity45 unfortunately latest study show although 85 parent child autism reported developmental concern child 36',\n",
              "   '25 354359 baio j wiggins l christensen dl maenner mj daniel j warren z kurziusspencer zahorodny w robinsonrosenberg c white durkin m imm p nikolaou l yearginallsopp lee lc harrington r lopez fitzgerald rt hewitt pettygrove constantino jn vehorn shenouda halllande j van naardenbraun k dowling nf 2018 prevalence autism spectrum disorder among child aged 8 year autism developmental disability monitoring network 11 site united state 2014 mmwr surveillance summary 676 123 barger bd campbell jm mcdonough jd 2013 prevalence onset regression within autism spectrum disorder metaanalytic review journal autism developmental disorder 434 817828 pubmed 22855372 chawarska k paul r klin hannigen dichtel le v olkmar f 2007 parental recognition developmental problem toddler autism spectrum disorder journal autism developmental disorder 371 6272 pubmed 17195921 cicchetti dv v olkmar f klin showalter 1995 diagnosing autism using icd10 criterion comparison neural network standard multivariate procedure',\n",
              "   'dev disord 37 2536 2007 33 morgan l wetherby barber repetitive stereotyped move ments child autism spectru disorder late second year lifej child psychol psychiatry 498 2 6837 2008 34 elison j et al repetitive beh avior 12montholds later classi ed autism spectrum disorder j acad child adolesc psychiatry 531 2 1 6 1224 2014 35 wolff j j et al longitudinal pattern repetitive behavior toddler autism j child psychol psychiatry 559 4 5953 2014 36 phagava h et al general movement infant autism spectrum dis order georgian med n 1561 0 0105 2008 3 7 l b e r u k h e p e r k r w l n r j l e ne motor grasping skill 6monthold infant high risk autism child dev 85 22182231 2014 38 bedford r et al precursor social communication dif culties infant atrisk autism gaze following attentional engagement j autism dev disord 42 2208 2218 2012 3 9 e l b b g h e ta l w h ty u e ei sw h ty ug e c n e x u lm u l f face scanning typical atypical development soc cogn affect neurosci 95 3 8543 2014 4 0 j n e w k l'],\n",
              "  'Summaries': ['\\n \\nThe text describes a research project that involved developing aspect technology to study autism. The project was led by Dawson Sapiro, Carpenter Hashemi, Campbell Espinosa, Baker Egger, and Duke University. The researchers referenced several studies, including one by Adrien J. L. Faure, Perrot Hameury, L. Garreau, and B. Barthelemy C. Sauvage (1991) on autism in families, and another by Bal V. H. Kim, H. Fok, Lord, and others (2019) on the symptoms of autism spectrum disorder in adolescents and young adults. The text also mentions a study by Baranek (1999) on sensory-motor, social behavior in infants, and a study by Bieberich and Morgan (2004) on self-regulation.',\n",
              "   '\\n \\nThe article discusses the use of the Infant Toddler Checklist (ITC) and the Broadband Screener (BBSC) to validate the presence of Autism Spectrum Disorder (ASD) in infants and toddlers at 9 months and 24 months old. The study found that the ITC and BBSC were effective in identifying children with ASD at these ages. Additionally, the article mentions a previous study by Zwaigenbaum et al. (2005) which examined the behavioral manifestations of autism in the first year of life, and another study by Young et al. (2015) which made recommendations for early screening of ASD in practice and research settings.',\n",
              "   \"\\n \\nThe text describes a study that evaluated the accuracy of an autism screening tool for children aged 48 months. The study found that the screening tool outperformed previous studies, with a sensitivity of 90% and a specificity of 90%. The study also found that the screening tool was able to accurately identify children with autism spectrum disorder (ASD), even if they had mild symptoms or were nonverbal. Additionally, the study found that the screening tool was able to diagnose ASD within the first year of life, which can improve the outlook for the child's development. However, the study also noted that some parents and children with ASD reported developmental concerns, even though they did not meet the diagnostic criteria for ASD.\",\n",
              "   '\\n \\nThe text discusses a study that examined the prevalence of Autism Spectrum Disorder (ASD) among children aged 8 years old in the United States. The study was conducted by the Autism Developmental Disability Monitoring Network, which is a program that tracks the incidence of ASD across 11 sites in the US. The study found that the prevalence of ASD among children aged 8 years old in the US was 1 in 54.\\n\\nAnother study was also mentioned, which looked at the onset and regression of autism spectrum disorders. This study used a meta-analytic review and found that there were no clear patterns for the onset or regression of autism spectrum disorders.\\n\\nA third study was discussed, which focused on parental recognition of developmental problems in toddlers with autism spectrum disorder. This study used a neural network standard multivariate procedure to compare the diagnostic criteria for autism using ICD10.\\n\\nOverall, the text highlights several studies that have been conducted on autism spectrum disorder, including its prevalence, onset, and diagnosis.',\n",
              "   '\\n \\nThe text discusses various studies related to autism spectrum disorders (ASD) in children. One study by Elison et al. classified repetitive behaviors as a subtype of ASD in 12-month-olds, while another study by Wolff et al. found a longitudinal pattern of repetitive behavior in toddlers with ASD. Phagava et al. also found that general movements are a precursor to social communication difficulties and gaze following in infants at high risk for ASD. Bedford et al. found that gaze following and attentional engagement are important factors in the development of social communication difficulties in infants at risk for ASD. Finally, Janssen et al. found that face scanning is an important factor in typical and atypical development in children with ASD.'],\n",
              "  'Result': '\\n \\nAutism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by challenges with social interaction, communication, and restricted interests or behaviors. It is a complex condition that affects individuals differently, and the severity of symptoms can vary widely. While the exact cause of ASD is unknown, it is believed to be influenced by a combination of genetic and environmental factors. Some studies suggest that certain genes may increase the risk of developing ASD, but the role of environment in the development of the condition is also significant. Environmental factors such as exposure to toxins, infections, and stress during pregnancy or early childhood may contribute to the development of ASD. Researchers continue to study the causes of ASD to better understand the underlying mechanisms and develop more effective interventions and treatments.'},\n",
              " {'Question': 'What is the cure of Autism Spectrum Disorder?',\n",
              "  'Retrieved Context': ['press springer andoxford university press dawson sapiro carpenter hashemi campbell espinosa baker egger helped develop aspect technology used inthe study technology licensed daw son sapiro carpenter hashemi espinosa baker egger duke university bene tednanciallyreferences adrien j l faure perrot hameury l garreau b barthelemy c sauvage 1991 autism familyhome movie preliminary ndings journal autism developmental disorder 211 43 49 adrien j l lenoir p martineau j perrot hameury l larmande c sauvage 1993 blind rating earlysymptoms autism based upon family home movie jour nal american academy child adolescent psy chiatry 323 617 626 19930500000019 bal v h kim h fok lord c 2019 autism spec trum disorder symptom age 2 19 year implicationsfor diagnosing adolescent young adult autismresearch 121 89 99 baranek g 1999 autism infancy retrospective video analysis sensorymotor social behavior 9 12 month age journal autism developmental disorder 293 213 224 bieberich morgan b 2004 selfregulation',\n",
              "   'funding national institute health travel reimbursement andor honorarium society clinical child adolescent psychology help group dr ozonoff received research grant funding national institute health autism speaks travel reimbursement honorarium editorial activity autism speaks autism science foundation wiley book royalty guilford press american psychiatric press inc dr schwichtenberg received grant funding national institute health travel support autism speaks autism science foundation author report financial disclosure potential conflict interest abbreviation asd autism spectrum disorder virsa videoreferenced infant rating system autism reference alqabandi gorter jw rosenbaum p 2011 early autism detection ready routine screening pediatrics 1281 e211e217 pubmed 21669896 arguel jamet e 2009 using video static picture improve learning procedural content computer human behavior 25 354359 baio j wiggins l christensen dl maenner mj daniel j warren z kurziusspencer zahorodny w',\n",
              "   'pmc 2021 january 01 author manuscript author manuscript author manuscript author manuscriptwetherby brosnanmaddox peace v newton l 2008 validation infanttoddler checklist broadbrand screener autism spectrum disorder 9 24 month age autism 125 487511 pubmed 18805944 zwaigenbaum l bryson rogers robert w brian j szatmari p 2005 behavioral manifestation autism first year life international journal developmental neuroscience 2323 143152 pubmed 15749241 zwaigenbaum l bauman ml fein pierce k buie davis pa newschaffer c robin dl wetherby choueiri r kasari c stone wl yirmiya n estes hansen rl mcpartland jc natowicz mr carter granpeesheh mailloux z smithroley wagner 2015 early screening autism spectrum disorder recommendation practice research pediatrics 136suppl 1 s41s59 pubmed 26430169 young et al page 10 j child psychol psychiatry author manuscript available pmc 2021 january 01 author manuscript author manuscript author manuscript author manuscriptkey point 1 sign asd present first two year',\n",
              "   'doi101007s1080300704447 40 parlade mv iverson jm development coordinated communica tion infant heightened risk autism spectrum disorder j autism dev disord 2015 45221834 doi 101007s10803015 2391z 41 campbell sb leezenbaum nb mahoney moore el brownell ca pretend play social engagement toddler high low genet ic risk autism spectrum disorder j autism dev disord 2016 46230516 doi101007s108030162764y 42 baroncohen autism empathizingsystemizing e th eory ann n acad sci 2009 11566880 doi 101111j174966322009 04467x 43 baroncohen lombardo mv auyeung b ashwin e knickmeyer r autism spectrum condition prevalent malesplos biol 2011 9e1001081 doi 101371journalpbio10 01081 44 markram h tania r kamila intense world syndromean alternative hypothesis autism front neurosci 2007 17796 doi103389neuro01110062007 45 samson ac huber gross jj emotion regulation aspergers syndrome highfunctioning autism emotion 2012 1265965 doi101037a0027975 conict interest author declare research conducted absence commercial',\n",
              "   'sensor letter deeplearningbased detection infant autism spectrum disorder using autoencoder feature representation jung hyuk lee1 geon woo lee1 guiyoung bong2 hee jeong yoo23and hong kook kim1 1school electrical engineering computer science gwangju institute science technology gwangju 61005 korea jhl gwl 2department psychiatry seoul national university bundang hospital seongnamsi gyeonggido 13620 korea gb hjy 3department psychiatry college medicine seoul national university seoul 03980 korea correspondence received 29 october 2020 accepted 24 november 2020 published 26 november 2020 gid00030gid00035gid00032gid00030gid00038gid00001gid00033gid00042gid00045 gid00001 gid00048gid00043gid00031gid00028gid00047gid00032gid00046 abstract autism spectrum disorder asd developmental disorder lifespan disability diagnostic instrument developed qualied based accuracy discrimination child asd typical development td child stability procedure disrupted limitation pertaining time expense subjectivity'],\n",
              "  'Summaries': ['\\n \\nThe text describes a research project that involved developing aspect technology to study autism. The project was led by Dawson Sapiro, Carpenter Hashemi, Campbell Espinosa, Baker Egger, and Duke University. The researchers referenced several studies, including one by Adrien J. L. Faure, Perrot Hameury, L. Garreau, and B. Barthelemy C. Sauvage (1991) on autism in families, and another by Bal V. H. Kim, H. Fok, Lord, and others (2019) on the symptoms of autism spectrum disorder in adolescents and young adults. The text also mentions a study by Baranek (1999) on sensory-motor, social behavior in infants, and a study by Bieberich and Morgan (2004) on self-regulation.',\n",
              "   '\\n \\nThe text describes various grants and funding opportunities for researchers in the field of autism and related disorders. Dr. Ozonoff received a research grant from the National Institute of Health, while Dr. Schwichtenberg received a grant from the Autism Science Foundation. Both researchers also received travel reimbursement and honorariums for their work. Additionally, there are mentions of an editorial activity grant from Autism Speaks and a book royalty from Wiley. The text also includes references to several studies on early autism detection, including one by Argel Jamet et al. (2009) that used video and static pictures to improve learning procedures for children with autism spectrum disorder (ASD).',\n",
              "   '\\n \\nThe article discusses the use of the Infant Toddler Checklist (ITC) and the Broadband Screener (BBSC) to validate the presence of Autism Spectrum Disorder (ASD) in infants and toddlers at 9 months and 24 months old. The study found that the ITC and BBSC were effective in identifying children with ASD at these ages. Additionally, the article mentions a previous study by Zwaigenbaum et al. (2005) which examined the behavioral manifestations of autism in the first year of life, and another study by Young et al. (2015) which made recommendations for early screening of ASD in practice and research settings.',\n",
              "   \"\\n \\nThe text describes several studies related to autism spectrum disorder (ASD) and its risk factors. One study found that infants with a higher risk of ASD had lower communication and socialization skills, while another study found that pretend play and social engagement were important for toddlers' development. Another study examined the theory of autism and found that individuals with ASD have difficulty with systemizing and empathy. The prevalence of autism spectrum conditions was also discussed in relation to males and plos biol. Emotion regulation was also studied in relation to Asperger's syndrome and high-functioning autism. The authors declared that their research was conducted without any commercial interests.\",\n",
              "   '\\n  The text describes a research paper that presents a deep learning-based detection system for infant autism spectrum disorder (ASD) using an autoencoder feature representation. The study was conducted by researchers from Gwangju Institute of Science and Technology in Korea, and it was published in November 2020. The paper aims to develop a diagnostic instrument that is qualified, accurate, and discriminatory, with the ability to detect ASD in children with typical development and stability procedures. The system takes into account limitations such as time expense, subjectivity, and disruption of the procedure.'],\n",
              "  'Result': '\\n \\nBased on my research findings, there is currently no cure for Autism Spectrum Disorder (ASD). However, there are various therapies and interventions available to help individuals with ASD improve their communication, socialization, and other skills. These include behavioral therapy, speech therapy, occupational therapy, and other forms of intervention. Some studies have also shown that early intervention can be beneficial for individuals with ASD. It is important to note that each individual with ASD is unique and may require different types of therapy or intervention.'},\n",
              " {'Question': 'What are Stereotypical and maladaptive behaviors in Autism Spectrum, how are these detected and managed?',\n",
              "  'Retrieved Context': ['psychiatric association diagnostic statistical manual mental disorder 4 washington dc author 2000 text rev baranek gt autism infancy retrospective video analysis sensorymotor social behavior 912 month age journal autism developmental disorder 1999 29213 224 pubmed 10425584 baranek gt david fj poe md stone wl watson lr sensory experience questionnaire discriminating sensory feature young child autism developmental delay typical development journal child psychology psychiatry 2006 476591601 pubmed 16712636 baranek gt watson lr boyd ba poe md david fj mcguire l hyporesponsiveness social nonsocial sensory stimulus child autism child developmental delay typically developing child development psychopathology 2013 252013307320 pubmed 23627946 bleile km stark mcgowan j speech development child decannulation evidence babbling facilitates later speech development clinical linguistics phonetics 1993 7319337 center disease control prevention prevalence autism spectrum disorder autism',\n",
              "   'dev disord 37 2536 2007 33 morgan l wetherby barber repetitive stereotyped move ments child autism spectru disorder late second year lifej child psychol psychiatry 498 2 6837 2008 34 elison j et al repetitive beh avior 12montholds later classi ed autism spectrum disorder j acad child adolesc psychiatry 531 2 1 6 1224 2014 35 wolff j j et al longitudinal pattern repetitive behavior toddler autism j child psychol psychiatry 559 4 5953 2014 36 phagava h et al general movement infant autism spectrum dis order georgian med n 1561 0 0105 2008 3 7 l b e r u k h e p e r k r w l n r j l e ne motor grasping skill 6monthold infant high risk autism child dev 85 22182231 2014 38 bedford r et al precursor social communication dif culties infant atrisk autism gaze following attentional engagement j autism dev disord 42 2208 2218 2012 3 9 e l b b g h e ta l w h ty u e ei sw h ty ug e c n e x u lm u l f face scanning typical atypical development soc cogn affect neurosci 95 3 8543 2014 4 0 j n e w k l',\n",
              "   'funding national institute health travel reimbursement andor honorarium society clinical child adolescent psychology help group dr ozonoff received research grant funding national institute health autism speaks travel reimbursement honorarium editorial activity autism speaks autism science foundation wiley book royalty guilford press american psychiatric press inc dr schwichtenberg received grant funding national institute health travel support autism speaks autism science foundation author report financial disclosure potential conflict interest abbreviation asd autism spectrum disorder virsa videoreferenced infant rating system autism reference alqabandi gorter jw rosenbaum p 2011 early autism detection ready routine screening pediatrics 1281 e211e217 pubmed 21669896 arguel jamet e 2009 using video static picture improve learning procedural content computer human behavior 25 354359 baio j wiggins l christensen dl maenner mj daniel j warren z kurziusspencer zahorodny w',\n",
              "   'child psychology psychiatry allied discipline 1995 36813651382 lord c rutter dilavore p risi autism diagnostic observation schedule ado los angeles ca western psychological service 1999 lynch mp oller dk steffens ml levine sl basinger umbel v onset speechlike vocalization infant syndrome american journal mental retardation 1995 10016886 pubmed 7546639 lynch mp oller dk steffens ml buder eh phrasing prelinguistic vocalization developmental psychobiology 1995 28323 pubmed 7895922 manjiviona j prior comparison asperger syndrome highfunctioning autistic child test motor impairment journal autism developmental disorder 1995 252329 pubmed 7608032 masataka n early linguistic milestone delayed child williams syndrome late onset hand banging possible ratelimiting constraint emergence canonical babbling developmental science 2001 4158164 matson jl fodstad jc dempsey symptom predict diagnosis autism pddnos infant toddler developmental delay using baby infant screen autism trait developmental',\n",
              "   'evidence either noticed specifically suggesting possibility asd coding thus single case intended blinding coder diagnostic group seems foiled coder observe stereotypic behavior vocal otherwise sample second infant engaged high canonical babble production roughhousing father clinical eye behavior seem particularly unusual research possibility babbling focus motor stereotypy asd seems order may worthy ofpatten et al page 16 j autism dev disord author manuscript available pmc 2014 october 01 nihpa author manuscript nihpa author manuscript nihpa author manuscriptnote two outlier car score 25 31 fell within range score asd group 2350 addition finding suggesting possible clinically useful marker asd present result provide new scientific view robustness canonical babbling prior empirical indication canonical babbling onset delayed asd volubility low infant later diagnosed asd result thus suggest development vocalization infancy affected whatever fundamental disorder asd may assuming asd'],\n",
              "  'Summaries': ['\\n \\nThe text discusses various studies and research related to autism. One study used a retrospective video analysis to examine sensory-motor, social behavior, and other features in children with autism at different ages. Another study developed a questionnaire to discriminate sensory features in young children with autism. A third study examined hyporesponsiveness to social and nonsocial stimuli in children with autism. Additionally, a study on speech development found that babbling can facilitate later speech development in children with autism. Finally, a study on the prevalence of autism spectrum disorders found that autism affects a significant number of individuals.',\n",
              "   '\\n \\nThe text discusses various studies related to autism spectrum disorders (ASD) in children. One study by Elison et al. classified repetitive behaviors as a subtype of ASD in 12-month-olds, while another study by Wolff et al. found a longitudinal pattern of repetitive behavior in toddlers with ASD. Phagava et al. also found that general movements are a precursor to social communication difficulties and gaze following in infants at high risk for ASD. Bedford et al. found that gaze following and attentional engagement are important factors in the development of social communication difficulties in infants at risk for ASD. Finally, Janssen et al. found that face scanning is an important factor in typical and atypical development in children with ASD.',\n",
              "   '\\n \\nThe text describes various grants and funding opportunities for researchers in the field of autism and related disorders. Dr. Ozonoff received a research grant from the National Institute of Health, while Dr. Schwichtenberg received a grant from the Autism Science Foundation. Both researchers also received travel reimbursement and honorariums for their work. Additionally, there are mentions of an editorial activity grant from Autism Speaks and a book royalty from Wiley. The text also includes references to several studies on early autism detection, including one by Argel Jamet et al. (2009) that used video and static pictures to improve learning procedures for children with autism spectrum disorder (ASD).',\n",
              "   '\\n \\nThe text describes a study conducted in 1995 by Lord, C. R., Dilavore, P., Risi, A., and Autism Diagnostic Observation Schedule (ADO) in Los Angeles, CA at Western Psychological Service. The study aimed to investigate the use of the ADO in diagnosing autism spectrum disorders (ASD). The authors found that the ADO was effective in diagnosing ASD and that it could be used to compare different subgroups of children with ASD, such as those with Asperger syndrome or high-functioning autism. The study also examined the relationship between motor impairment and the development of language in children with ASD. Additionally, the study compared the development of prelinguistic vocalization in infants with ASD to that of typically developing infants. The authors concluded that the ADO was a useful tool for diagnosing and studying ASD and that further research was needed to understand the underlying mechanisms of language development in children with ASD.',\n",
              "   \"\\n \\nThe text describes a study that aimed to investigate the relationship between vocalization and motor stereotypy in children with Autism Spectrum Disorder (ASD). The study used a single-case design, with a coder who observed the child's behavior and diagnosed them as having ASD. However, the coder noticed stereotypic behavior and vocalizations that were not typical of ASD, leading to questions about the validity of the diagnosis. The study found that two outliers in the child's scores fell within the range for the ASD group, but also suggested that there may be a clinically useful marker for ASD present in the results. The study provides a new scientific view on the robustness of canonical babbling, which has been previously indicated as an early indicator of ASD onset. The study suggests that vocalization in infancy is affected by a fundamental disorder in ASD, and that further research is needed to understand the relationship between vocalization and motor stereotypy in children with ASD.\"],\n",
              "  'Result': '\\n \\nStereotypical and maladaptive behaviors in Autism Spectrum Disorders (ASD) include repetitive behaviors, restricted interests, and social communication difficulties. These behaviors can vary widely among individuals with ASD and can impact their daily functioning.\\n\\nRepetitive behaviors, such as hand flapping, lining up objects, or repeating phrases, are common in individuals with ASD. These behaviors can be adaptive in some situations, such as providing comfort or reducing anxiety, but they can also interfere with daily activities and social interactions.\\n\\nRestricted interests can also be seen in individuals with ASD. They may have intense interests in specific topics or objects, such as trains or cars, and may struggle to shift their attention to other tasks or activities. This can make it difficult for them to engage in typical social activities and interact with others.\\n\\nSocial communication difficulties are also common in individuals with ASD. They may struggle with initiating and maintaining conversations, understanding nonverbal cues, and recognizing social norms. This can lead to difficulties in forming and maintaining relationships with others.\\n\\nThese behaviors can be detected through observation and assessment by trained professionals, such as psychologists or therapists. Various tools and assessments, such as the Autism Diagnostic Observation Schedule (ADOS), can be used to diagnose ASD and evaluate the severity of symptoms.\\n\\nOnce these behaviors are detected, various interventions and treatments can be implemented to manage them. Behavioral therapy, such as Applied Behavior Analysis (ABA), can be used to teach individuals with ASD appropriate behaviors and reduce maladaptive ones. Medications, such as antidepressants or stimulants, may also be prescribed to address certain symptoms.\\n\\nIt is important to note that every individual with ASD is unique, and their experiences and needs may differ. Therefore, personalized approaches and interventions should be considered when managing stereotypical and maladaptive behaviors in individuals with ASD.'},\n",
              " {'Question': 'How relevant is eye contact and how it can be used to detect Autism?',\n",
              "  'Retrieved Context': ['diagnostic validity j autism dev disord 37 613627 17 hashemi j et al proceeding eai international conference wireless mobile communication healthcare mobihealth 2015 18 de la torre f intraface proceeding ieee international conference automatic face gesture recognition workshop 2015 19 dementhon ld modelbased object pose 25 line code international journal computer vision 15 123141 1995 20 hashemi j et al computer vision tool lowcost noninvasive measurement autismrelated behavior infant autism re treat 2014 935686 21 hashemi j et al computer vision analysis quantification autism risk behavior ieee transaction affective computing 11 2018 22 heiser p et al objective measurement hyperactivity impulsivity inattention child hyperkinetic disorder treatment methylphenidate european child adolescent psychiatry 13 100104 03653 2004 23 reiersen constantino j n todd r cooccurrence motor problem autistic symptom attentiondeficithyperactivity disorder j acad child adolesc psychiatry 47 662672 24',\n",
              "   'diagnosing autism using icd10 criterion comparison neural network standard multivariate procedure child neuropsychology 1 2637 clark harrington r 1999 diagnosing rare disorder rarely appropriate use screening instrument journal child psychology psychiatry 402 287290 pubmed 10188711 gammer bedford r elsabbagh garwood h pasco g tucker l v olein johnson mh charman basis team 2015 behavioral marker autism infancy score autism observational scale infant prospective study atrisk sibling infant behavior development 38 107115 pubmed 25656952 gangi dn boterberg schwichtenberg aj solis e young g iosif ozonoff 2019 use prospective longitudinal gaze measurement defining regression paper presented annual meeting international society autism research montreal 5 grime da schulz kf 2002 us abuse screening test lancet 359 881884 pubmed 11897304 young et al page 8 j child psychol psychiatry author manuscript available pmc 2021 january 01 author manuscript author manuscript author manuscript author',\n",
              "   'autism symptom severity change early childhoodjournal autism developmental disorder werner e dawson g osterling j dinno n 2000 brief report recognition autism spectrum disorder oneyear age retrospective study based home videotapesjournal autism developmental disorder 302 157162 yin l wei x sun wang j rosato j 2006 a3 facial expression database facial behavior research paper pres ented 7th international conference automatic faceand gesture recognition fgr06 university southamptonsouthampton uk yirmiya n kasari c sigman mundy p 1989 facial expression affect autistic mentally retarded normalchildren journal child psychology psychiatry 305725735 insar carpenter et aldigital behavioral phenotyping asd 12',\n",
              "   'contain test item judge autism child facial expression 14 item cab scale seventh item inexplicable laughter tenth item looking face avoiding eye contact related expression 57 item abc scale seventh item noncommunicative smile seventeenth item respond people facial expression twentyfourth item active avoidance eye contact others fifteen item car scale third emotional response pleasure unhappiness interest expressed change facial expression posture scale basically include item autism detection child facial expression show diagnosis autism accurate facial expression progress artificial intelligence technology facial expression recognition technology objectively effectively reflect mental health child used early diagnosis autism yanbin et al 2018 also communicated doctor hubei maternal child health hospital wuhan child hospital guangzhou woman child medical center many time actually checked process using autism diagnostic scale diagnose child doctor observes tester reaction determine',\n",
              "   'group difference rate head movement toddler watched movie depicting social nonsocial stimulus toddler asd exhibited significantly higher rate head movement compared nonasd toddler suggesting difficulty maintaining midline position head engaging attentional system use digital phenotyping approach computer vision analysis quantify variation early motor behavior allow precise objective quantitative characterization early motor signature potentially provide new automated method early autism risk identification although core symptom autism spectrum disorder asd defined atypical pattern social inter action presence stereotyped repetitive behavior interest evidence suggests difference motor function also important early feature autism motor delay could contribute early hallmark autism symptom including difficulty orienting name involving eye head turn coordinating head limb movement involved gaze following joint attention behavior pointing teitelbaum et al 1 found atypical movement eg shape'],\n",
              "  'Summaries': ['\\n \\nThe text describes various studies and research related to autism, developmental disorders, and mental health. The studies use different methods such as diagnostic validity, computer vision, and low-cost non-invasive measurements to analyze autism-related behavior, risk factors, and symptoms. Some of the studies focus on specific conditions like hyperactivity, inattention, and attention deficit hyperactivity disorder (ADHD), while others explore the relationship between autism and other conditions like child hyperkinetic disorder and motor problems. Overall, the text highlights the importance of objective measurement and quantification in understanding and treating autism and related disorders.',\n",
              "   '\\n \\nThe text discusses various studies and methods used to diagnose autism. One approach is to compare ICD-10 criteria using a neural network standard multivariate procedure in child neuropsychology. Another method involves using a behavioral marker, such as the Autism Observational Scale Infant Prospective Study, to identify at-risk siblings and track their behavior development over time. Gaze measurement has also been used to define regression in autism, with a paper presented at the annual meeting of the International Society for Autism Research. Additionally, an abuse screening test was found to be effective in identifying children at risk for autism in a study published in The Lancet.',\n",
              "   '\\n \\nThe text describes a study conducted by Werner E. Dawson, J. G. Osterling, J. Dinno, and N. in 2000 that aimed to recognize Autism Spectrum Disorder (ASD) based on one-year age retrospective study using home videotapes. The study found that children with ASD had different facial expressions compared to typically developing children. In 2006, Yin L. Wei, X. Sun, J. Rosato, J. presented a facial expression database at the 7th International Conference on Automatic Face and Gesture Recognition (FGR06). The paper focused on facial behavior research and its impact on autistic, mentally retarded, and normal children. In 1989, Yirmiya, Kasari, C. Sigman, and Mundy published a study in Journal of Child Psychology and Psychiatry that explored the relationship between facial expression, affect, and autism. Additionally, Insar Carpenter et al. conducted a digital behavioral phenotyping study in 2012 that focused on Autism Spectrum Disorder (ASD).',\n",
              "   '\\n  The text describes a study by Yanbin et al. (2018) that explored the use of facial expression recognition technology to detect autism in children. The study included 57 items on the ABC scale, which measures facial expressions and posture, as well as the car scale, which assesses emotional responses. The researchers found that facial expression recognition technology accurately reflected the mental health of children with autism, and that changes in facial expression and posture were related to changes in emotional response. The study also demonstrated the effectiveness of using facial expression recognition technology for early diagnosis of autism.',\n",
              "   '\\n \\nThe study examined the head movement of toddlers with and without Autism Spectrum Disorder (ASD) while watching a movie. The results showed that toddlers with ASD had a significantly higher rate of head movement compared to those without ASD, indicating difficulty maintaining midline position and engaging their attentional system. Digital phenotyping and computer vision analysis were used to quantify the variation in early motor behavior and provide a precise, objective characterization of the early motor signature. This could potentially lead to an automated method for early autism risk identification. While core symptoms of ASD are defined by atypical patterns of social interaction, evidence suggests that differences in motor function may also be important early features of autism, including motor delay and difficulty orienting, naming, and involving gaze following, joint attention behavior, and pointing. Teitelbaum et al. found atypical movement, such as shape, in toddlers with ASD.'],\n",
              "  'Result': '\\n  Eye contact is not specifically mentioned in the provided text as a reliable method for detecting autism. However, the text does mention that gaze measurement has been used to define regression in autism, and that changes in facial expression and posture are related to changes in emotional response. Therefore, while eye contact may be a component of these behaviors, it is not the sole indicator of autism. It is important to note that autism is a complex condition with a range of symptoms and behaviors, and no single method or measure can fully capture all aspects of autism. Diagnosis and treatment of autism typically involve a comprehensive evaluation by a team of professionals, including psychologists, psychiatrists, neurologists, and other specialists.'},\n",
              " {'Question': 'How can cross country trials help in the development of Machine learning based Multimodal solutions?',\n",
              "  'Retrieved Context': ['improvement machine learningmethodology well improved method handling biasesbetween training data application setting new clinicaltrial larger sample size underway make possibleto validate new improvement resulting study well asto improve confidence high performance algorithm conclusion machine learning play important role improving effectiveness behavioral health screener achieved significant improvement established screening tool autism inchildren demonstrated multicenter clinical trial havealso shown important pitfall applying machine learningin domain quantified benefit applying proper solu tions address funding research received specific grant funding agency pub lic commercial notforprofit sector competing interest author affiliated cognoa inc employment andor advisory capacity contributor listed author contributed study design well drafting revision paper author approve final version paper published agree accountable allaspects worksupplementary material supplementary material',\n",
              "   'extension poseinvariant crossmodal dictionary learning approach originally described hashemi et al training thedictionary representation setup map facial informa tion 2d 3d modality able infer discriminative facial information facial expression recognition even 2d facial image available deployment training data bing hamton university 3d facial expression database yinwei sun wang rosato 2006 used along synthesized face image varying pose see hashemi et al 2015 synthesis detail extracted image featuresand distance subset facial landmark used facial feature learn robust dictionary lastly using inferred discriminative 3d frontal2d facial feature multiclass support vector machine chang lin 2011 trained classify different facial expression recent year progress automatic facial expression analysis child toddler dy malti 2016 gadea alioespert salvador 2015 haines et al 2019 lobue thrasher 2014 messinger mahoor chow cohn 2009 addition previouslyvalidated cva algorithm expert human rater coding',\n",
              "   'type underwent vefold crossvalidation training bestperforming model chosen model trained tensorflow framework 33 comparison svm model linear kernel trained data split proposed deep learning model well vanilla blstm suggested single blstm eight cell sensor 2020 20 x peer review 8 12 figure 2 structure joint optimization model auto encoder ae bidirectional long short term memory blstm 3 performance evaluation performance method evaluated five fold cross validation 95 average asd utterance 130 average td utterance proportionally distributed five case vocalization gener alized estimation unconcentrated utterance data averaged performance five validation split model described table 4 labeled name blstm used feature training blstm model egemaps 88 deno te 88 feature egemaps egemaps 54 denotes 54 feature selected mann whitney u test aeencoded denotes joint optimized model classification stage one utterance processed frame wise method softmax output c onverted class index 0 1 average class',\n",
              "   'j devin ghemawat irving g isard et al tensorflow system largescale machine learning proceeding 12th usenix symposium operating system design implementation savannah ga usa 24 november 2016 pp 265283 34 schuller b steidl batliner interspeech 2009 emotion challenge proceeding annual conference international speech communication association interspeech brighton uk 610 september 2009 pp 312315 35 van der maaten l hinton g visualizing data using tsne j mach learn re 2008 9 25792605 publisher note mdpi stay neutral regard jurisdictional claim published map institutional aliations 2020 author licensee mdpi basel switzerland article open access article distributed term condition creative common attribution cc license http creativecommonsorg license by40',\n",
              "   '1 semantically meaningful value 0 inconse quential end augmented training set duplicate sample feature value flipped 1 0 injection 0 randomly performed probability thesampleweighted ratio positive negative sample thevalue particular feature 0 50 ratio ensurethat tree random forest much le likely drawconclusions absence feature combination desirable combine questionnaire video screener toachieve higher accuracy however needed overlapping trainingset available instead clinical validation dataset itselfwas used train combination model numerical response parent questionnaire video classifier combined using l2regularized logistic regression advantage reducing concern overfittingparticularly given logistic model three free parametersbootstrapping cross validation study showed overfitting may present procedure detectable withinstatistical limitation since individual method wassiloed age separate combination algorithm trained per agegroup silo combination algorithm optimal inconclusiveoutput'],\n",
              "  'Summaries': ['\\n \\nThe text describes a study that aimed to improve the effectiveness of a behavioral health screener for autism in children. The study used machine learning methodology and was conducted in a clinical trial with a larger sample size. The results showed a significant improvement in the screening tool, which was validated through the use of a multicenter clinical trial. However, the text also highlights an important pitfall in applying machine learning in the domain of quantifying benefits, which requires proper solutions to be addressed. The study was funded by a specific grant from a public-commercial nonprofit sector, and the authors involved had competing interests and affiliations with Cognoa Inc. The author of the study contributed to the study design, drafting, revision, and final approval of the paper, which was published and made available as supplementary material.',\n",
              "   \"\\n \\nThe text describes a crossmodal dictionary learning approach for facial expression recognition. The approach is able to infer discriminative facial information from both 2D and 3D modalities, and can be deployed with training data from Bing Hamton University's 3D facial expression database. The method uses synthesized face images and extracts image features and distances from facial landmarks to learn a robust dictionary. This dictionary is then used to classify different facial expressions using a multiclass support vector machine. Recent progress in this field includes the use of automatic facial expression analysis for children and toddlers, as well as validation with expert human raters and coding.\",\n",
              "   '\\n \\nThe text describes a study that compared different models for speech recognition using cross-validation. The best performing model was chosen and trained using TensorFlow framework 3.3. The study also included a comparison with an SVM model with a linear kernel, and a deep learning model with a vanilla BLSTM architecture. The deep learning model had an eight-cell sensor and was trained on data split into five folds. Performance was evaluated using five-fold cross-validation, and the results showed an average accuracy of 95% for ASD utterances and 130% for TD utterances. The study also included a discussion of joint optimization and autoencoder models, as well as a comparison of different feature selection methods using Mann-Whitney U tests. Finally, the study presented a table describing the performance of the labeled models and discussed the use of softmax output conversion in the classification stage.',\n",
              "   '\\n \\nThe text describes several papers presented at various conferences and symposiums related to large-scale machine learning, operating systems, and speech recognition. The first paper discusses the use of TensorFlow for implementing large-scale machine learning systems, while the second paper focuses on the emotion challenge in interspeech 2009. The third paper presents a method for visualizing data using t-SNE (t-distributed stochastic neighbor embedding), which was introduced in 2008. Finally, the fourth paper discusses the use of MDPI as a publisher for articles that are open access and distributed under the Creative Commons Attribution CC license.',\n",
              "   '\\n \\nThe text describes a study that aimed to improve the accuracy of a model for predicting a numerical response by combining a questionnaire and a video screener. The study used a random forest algorithm with L2 regularized logistic regression to reduce overfitting. However, the results were inconclusive due to overfitting, which could not be detected within statistical limitations. The study also explored the use of an overlapping training set and clinical validation dataset instead of a separate questionnaire and video screener.'],\n",
              "  'Result': '\\n  Cross-country trials can help in the development of machine learning-based multimodal solutions by providing a diverse range of data and testing the performance of the solution in different cultural and linguistic contexts. By conducting trials in multiple countries, researchers can gain insights into how the solution performs across different populations and environments, which can inform future improvements and adaptations. Additionally, cross-country trials can help to validate the generalizability of the solution and ensure that it is effective in real-world settings. Overall, cross-country trials can provide valuable feedback and guidance for developing machine learning-based multimodal solutions that are effective and appropriate for global audiences.'},\n",
              " {'Question': 'How early infants cry can help in the early detection of Autism?',\n",
              "  'Retrieved Context': ['j dickinson h lord c early indicator autism spectrum disorder second year lif ej autism devdisord 20043447393doi101007s108030042544y 8 barbaro j dissanayake c early marker autism spectrum disorder infant toddler prospectively identied social attention communication study autism 2013 176486 doi1011771362361312442597 9 zwaigenbaum l bauman ml stone wl yirmiya n estes hansen rl et al early identication autism spectrum disorder recommendati ons practice research pediatrics 2015 4892102 136suppl 1s1040 doi101542peds20143667c 10 cassel td messinger d ibanez lv haltigan jd acosta si buchman ac early social emotional communication infant sibling child frontier pediatrics wwwfrontiersinorg 8 june 2020 volume 8 article 290qiu et al early screening highrisk asd autism spectrum disorder examination broad phenot ypej autismdevdisord 20073712232doi101007s1080300603371 11 heimann laberg ke norden b imitative interaction increas e social interestandelicitedimitationinnonverbalchildrenwithauti',\n",
              "   'screening tool infant demonstrating either low canonical babbling ratio low volubility intervention draw infant attention socialcommunicative stimulus context dyadic interaction may help stimulate growth vocal communication acknowledgment research made possible grant national institute child health human development r01hd42168 grant cure autism foundation sensorymotor social communicative symptom autism infancy thank family whose participation made study possible staff collected processed data projectpatten et al page 18 j autism dev disord author manuscript available pmc 2014 october 01 nihpa author manuscript nihpa author manuscript nihpa author manuscriptreferences acevedo mc role acculturation explaining ethnic difference prenatal healthrisk behavior mental health parenting belief mexican american european american risk woman child abuse neglect 2000 24111127 pubmed 10660014 american psychiatric association diagnostic statistical manual mental disorder 4 washington dc author 2000',\n",
              "   'et al page 3 j autism dev disord author manuscript available pmc 2014 october 01 nihpa author manuscript nihpa author manuscript nihpa author manuscriptbe depressed compared typically developing infant however infant lower socioeconomic status s shown consistently produce fewer utterance per minute middle high s peer eilers et al 1993 oller et al 1995 research suggests child low s experience le communication caregiver hart risley 1995 snow 1995 lower volubility infant may product decreased socialcommunication adult potentially resulting lower level social motivation infant variability momenttomoment parental interactivity clearly affect infant volubility middle first year life indicated research parentinfant interaction stillface paradigm work suggests strong tendency particular case parent stillface infant increase vocalization rate specifically volubility baseline period one three minute facetoface vocal interaction substantially lower following stillface period one three minute',\n",
              "   'h yamasue h 2018 computeranalyzed facial expression surrogate marker autism spectrum social core symptom plo one 131 e0190442 rice e harris g 2005 comparing effect size followup study roc area cohen sd r law human behavior 295 615 620 s1097900568327 robin l casagrande k barton chen c dumont mathieu fein 2014 validation modi ed checklist autism toddler revised followup mchatrf pediatrics 1331 37 45 1542peds20131813 samad diawara n bobzien j l harrington j w witherow iftekharuddin k 2018 afeasibility study autism behavioral marker spontaneousfacial visual hand movement response data ieeetransactions neural system rehabilitation engineering 262 353 361 2768482 snow e hertzig e shapiro 1987 expression emotion young autistic child journal theamerican academy child adolescent psychiatry 266 836 838 00006 sullivan w lewis 2003 emotional expression young infant child practitioner primer infant young child 162 120 142 10970000116320030400000005 tantam holmes cordess c 1993 nonverbal expres',\n",
              "   'child watched series developmentally appropriate movie facial expression recorded using camera embedded tablet result suggest computational assessment facial expression may useful early detec tion symptom autism keywords autism risk behavior facial expression computer vision early detection introduction autism spectrum disorder asd reliably diagnosed early 24 month old risk sign detected early 6 12 month old dawson bernier 2013 luyster et al 2009 despite aver age age diagnosis united state remains around 4 year age christensen et al 2016 mixed evidence stability autism trait early childhood bieleninik et al 2017 waizbardbartov et al 2020 delay diagnosis still impact timely intervention critical window development inresponse 2007 american academy pedi atrics published guideline supporting need child screened asd 18 and24months age part wellchild visit myersjohnson council child disability 2007current screening typically relies caregiver reportsuch modi ed checklist asd toddler revised'],\n",
              "  'Summaries': ['\\n \\nThe text discusses various studies and research related to early identification of Autism Spectrum Disorder (ASD) in infants, toddlers, and children. The authors recommend practices for early identification and emphasize the importance of social attention, communication, and imitative interaction in identifying ASD. Some studies have used examinations and broad phenotype assessments to screen for ASD, while others have focused on nonverbal children with ASD. Overall, the text highlights the need for continued research and practice in the field of early identification of ASD.',\n",
              "   \"\\n \\nThe text describes a study that used a screening tool to assess infants' communication skills. The study found that interventions such as drawing attention, social-communicative stimuli, and dyadic interactions can help stimulate growth in vocal communication. The study was made possible by a grant from the National Institute of Child Health and Human Development, and was conducted by researchers at the University of California, Los Angeles. The study also examined the role of acculturation in explaining ethnic differences in prenatal health, risk behavior, mental health, and parenting beliefs among Mexican American and European American women. The study found that Mexican American women were more likely to experience child abuse and neglect than European American women.\",\n",
              "   \"\\n \\nThe text discusses a study on autism and developmental disorders, which found that infants from lower socioeconomic backgrounds tend to have fewer utterances per minute compared to typically developing infants. However, research suggests that children with low social experiences may have decreased social communication and motivation. The study also found that parental interactivity can affect an infant's volubility, with a strong tendency for parent-stillface interactions to increase an infant's vocalization rate.\",\n",
              "   \"\\n \\nThe text describes various studies and research related to facial expressions, autism, and social symptoms. One study used surrogate markers to analyze facial expressions in individuals with autism spectrum disorder (ASD) and found that they had reduced social core symptoms. Another study compared the effect sizes of different methods for measuring social communication skills in children with ASD. Another study validated a modified checklist for assessing autism in toddlers and found it to be reliable and valid. An feasibility study was conducted on using facial visual hand movement response data as a behavioral marker for autism, and it showed promising results. The text also mentions a study from 1987 that explored the relationship between facial expression, emotion, and young autistic children. Finally, a study from 2003 focused on emotional expression in young infants and children, and it provided a practitioner's primer on the topic.\",\n",
              "   '\\n \\nThe article discusses the use of a computational assessment that records facial expressions on a tablet to detect symptoms of autism in children. The study suggests that this method could be useful for early detection, which is important for timely intervention. Despite advances in technology, the average age of autism diagnosis in the United States remains around four years old. Early detection can help identify risk signs in children as young as six months old. However, there is mixed evidence about the stability of autism traits in early childhood. The American Academy of Pediatrics published a guideline in 2007 recommending that children be screened for autism spectrum disorder (ASD) at 18 and 24 months of age during well-child visits. Current screening methods typically rely on caregiver reports, such as the ASD Toddler Revised Checklist.'],\n",
              "  'Result': \"\\n \\nThere is no direct mention in the given text about how early infants' crying can help in the early detection of Autism. However, the text does discuss various studies and research related to early identification of Autism Spectrum Disorder (ASD) in infants, toddlers, and children. It emphasizes the importance of social attention, communication, and imitative interaction in identifying ASD. Some studies have used examinations and broad phenotype assessments to screen for ASD, while others have focused on nonverbal children with ASD. The text highlights the need for continued research and practice in the field of early identification of ASD.\"},\n",
              " {'Question': 'What are various methods to detect Atypical Pattern of Facial expression in Children?',\n",
              "  'Retrieved Context': ['recorded child facial expression com puter vision analysis cva automatically detected tracked facial landmark used estimate head position facial expression positive neutral using cva speci c point throughout movie identi ed reliably differentiate child without asd based pattern facial movement expression area curve individual movie ranging 062 073 instance child asd frequently displayed neutral expression compared child without asd expression frequency expression driven nonasd child often displaying raised eyebrow open mouth characteristic engagementinterest preliminary result suggest computational coding facial movement expression via tabletbased assessment detect difference affective expression one early core feature asd autism re 2020 00 1 12 2020 international society autism research wiley periodical llc lay summary study tested use tablet behavioral assessment young child autism child watched series developmentally appropriate movie facial expression recorded using camera',\n",
              "   'recognition rate seven expression test child 1 test child 10 857 percent 857 percent 857 percent 571 percent 857 percent 100 percent 714 percent 100 percent 857 percent 571 percent respectively average recognition rate 814 percent judging 60 percent threshold two test child facial expression recognition rate 571 percent show real environment algorithm system affected environment light accuracy affected certain extent however according accuracy 814 percent basically meet preliminary diagnostic requirement whether expression abnormal future real sample added improve accuracy system algorithm experimental result show error mainly concentrate expression disgust surprise main reason follows 1 disgust surprise minor local change face two kind expression significant distinguishing feature 2 participant little change two facial expression obvious feature corresponding category approached neutral expression easy confuse table iii average recognition rate expression angry 50 percent disgust 10',\n",
              "   'digital medicine 11 20 ekman p 2003 emotion revealed 2nd ed new york ny time book ekman r 1997 face reveals basic applied stud y spontaneous expression using facial action codingsystem facs new york ny oxford university press filliter j h longard j lawrence zwaigenbaum l brian j garon n bryson e 2015 positive affect infant sibling child diagnosed autism spectrumdisorder journal abnormal child psychology 433 567575 fischler bolles r c 1981 random sample consen sus paradigm model tting application image analysis automated cartography communication theassociation computing machinery 246 381 395 gadea alio espert r salvador 2015 deceit facial expression child enabling role thepoker face child dependent personality detector frontier psychology 6 1089 1089 org103389fpsyg201501089 gangi n ibanez l v messinger 2014 joint atten tion initiation without positive affect risk group difference association asd symptom journal ofautism developmental disorder 446 1414 1424 gotham k risi pickle lord c',\n",
              "   'child difficult collect child sf c l image order improve recognition rate child facial expression cooperated amy education school zhengzhou sixteen healthy child volunteer recruited collect facial expression data collected seven kind expression totaling 112 picture child 5 8 year old including 8 boy 8 girl acquisition environment quiet external interference highd efinition camera used collect facial expression image processed professionally bef ore collecting facial expression data parent informed purpose f collecting facial expression data questioning parent child participated collection facial expression data history autism loaded expression data training sample library purpose collecting chinese child facial expression data increase number chinese child facial expression sample training sample improve recognition rate system child facial expression collection process collected child facial expression data shown plate 3 42 network topology according network environment equipment',\n",
              "   'duction eye gaze positive facial emotion increase negative emotion transitioning baseline episo de sf episode 13 eect recognized termed sf eect relevant study researcher also fo und reason generation sf eect infant toddler disappearance social response eye contact mother show still face disappearanceofsocialsignalscausestheappearanceofnegati emotion infant toddler 23 rst two episode often used research randomly presented order inthe past decade basic setting sfp used method explore early childhood social behavior 2426 reason study chosen rst twoepisodes present study participant mother videorecordedduringthesfpinadesignatedobservationro om atthetimeofenrollmentthemotherwassittingoppositetothe childinteractedwiththechildfor2minunderxedinstruc tions stopped interaction maintained neutral face 1min figure1 show setup experimental environmentandprocedure infant caregiver engagement phase icep 27 nichols et al 28 dene coding indicator follows 1 protest behavior infant show facial'],\n",
              "  'Summaries': ['\\n \\nThe text describes a study that used computer vision analysis (CVA) to analyze facial expressions of children with and without Autism Spectrum Disorder (ASD). The study recorded facial expressions of children using a camera and tracked facial landmarks to estimate head position and facial expression. The study found that children with ASD frequently displayed neutral expression, while children without ASD often displayed raised eyebrows and an open mouth. The study suggests that computational coding of facial movements and expression can be used to detect differences in affective expression in children with ASD. The study was published in the International Society for Autism Research journal in 2020.',\n",
              "   '\\n \\nThe text describes a study on facial expression recognition in children. The recognition rates for seven different expressions were tested on child 1 and child 10, with an average recognition rate of 814%. The algorithm was affected by changes in the environment and lighting conditions, but overall met the preliminary diagnostic requirements. The experimental results showed that errors mainly concentrated on expressions of disgust and surprise, which were difficult to distinguish due to minor changes in facial features.',\n",
              "   '\\n \\nThe text discusses various aspects of digital medicine, including emotion recognition and its applications in fields such as psychiatry and psychology. The Facial Action Coding System (FACS) is mentioned as a tool for analyzing facial expressions to reveal emotions. The book \"Emotion Revealed\" by Ekman and Rozin is also mentioned as a resource on the topic. The authors Longard, Zwaigenbaum, Garon, Bryson, Fischler, Bolles, and R. C. are cited for their work on this subject. The text also touches on the use of image analysis, automated cartography, communication, and computing machinery in the field of digital medicine.',\n",
              "   '\\n \\nThe text describes a project aimed at improving the recognition rate of facial expressions in children. The project involves recruiting a healthy child from Zhengzhou, China and collecting facial expression data using a high-definition camera. The data is then processed professionally before being collected. Parents are informed about the purpose of the data collection and participate in the process. The collected data is used to train a system for recognizing facial expressions in Chinese children. The network topology of the equipment used in the data collection process is shown in plates 3 and 42.',\n",
              "   '\\n \\nThe study explores the relationship between social signals and emotional responses in infants and toddlers. The researchers used a basic setting with a designated observation period during which the mother interacted with the child for two minutes under xed instructions, stopping interaction and maintaining a neutral face for one minute. The study found that the appearance of negative emotions in infants and toddlers was caused by the disappearance of social signals, specifically eye contact and still faces. The study is relevant to early childhood social behavior and has been conducted using the SFP method.'],\n",
              "  'Result': '\\n \\nThere are several methods to detect atypical patterns of facial expression in children. One such method is computer vision analysis (CVA), which uses facial landmark tracking to estimate head position and facial expression. This technique has been used to detect differences in affective expression in children with Autism Spectrum Disorder (ASD) compared to typically developing children. Another method is facial expression recognition, which involves testing recognition rates for different facial expressions on individual children. However, this method may be affected by changes in the environment and lighting conditions. Digital medicine techniques, such as the Facial Action Coding System (FACS) and image analysis, can also be used to analyze facial expressions and reveal emotions. Additionally, projects aimed at improving the recognition rate of facial expressions in children involve collecting and processing facial expression data using high-definition cameras and professional processing techniques.'},\n",
              " {'Question': 'What kind of facial expressions can be used to detect Autism Disorder in children?',\n",
              "  'Retrieved Context': ['autism symptom severity change early childhoodjournal autism developmental disorder werner e dawson g osterling j dinno n 2000 brief report recognition autism spectrum disorder oneyear age retrospective study based home videotapesjournal autism developmental disorder 302 157162 yin l wei x sun wang j rosato j 2006 a3 facial expression database facial behavior research paper pres ented 7th international conference automatic faceand gesture recognition fgr06 university southamptonsouthampton uk yirmiya n kasari c sigman mundy p 1989 facial expression affect autistic mentally retarded normalchildren journal child psychology psychiatry 305725735 insar carpenter et aldigital behavioral phenotyping asd 12',\n",
              "   'recorded child facial expression com puter vision analysis cva automatically detected tracked facial landmark used estimate head position facial expression positive neutral using cva speci c point throughout movie identi ed reliably differentiate child without asd based pattern facial movement expression area curve individual movie ranging 062 073 instance child asd frequently displayed neutral expression compared child without asd expression frequency expression driven nonasd child often displaying raised eyebrow open mouth characteristic engagementinterest preliminary result suggest computational coding facial movement expression via tabletbased assessment detect difference affective expression one early core feature asd autism re 2020 00 1 12 2020 international society autism research wiley periodical llc lay summary study tested use tablet behavioral assessment young child autism child watched series developmentally appropriate movie facial expression recorded using camera',\n",
              "   'contain test item judge autism child facial expression 14 item cab scale seventh item inexplicable laughter tenth item looking face avoiding eye contact related expression 57 item abc scale seventh item noncommunicative smile seventeenth item respond people facial expression twentyfourth item active avoidance eye contact others fifteen item car scale third emotional response pleasure unhappiness interest expressed change facial expression posture scale basically include item autism detection child facial expression show diagnosis autism accurate facial expression progress artificial intelligence technology facial expression recognition technology objectively effectively reflect mental health child used early diagnosis autism yanbin et al 2018 also communicated doctor hubei maternal child health hospital wuhan child hospital guangzhou woman child medical center many time actually checked process using autism diagnostic scale diagnose child doctor observes tester reaction determine',\n",
              "   'child watched series developmentally appropriate movie facial expression recorded using camera embedded tablet result suggest computational assessment facial expression may useful early detec tion symptom autism keywords autism risk behavior facial expression computer vision early detection introduction autism spectrum disorder asd reliably diagnosed early 24 month old risk sign detected early 6 12 month old dawson bernier 2013 luyster et al 2009 despite aver age age diagnosis united state remains around 4 year age christensen et al 2016 mixed evidence stability autism trait early childhood bieleninik et al 2017 waizbardbartov et al 2020 delay diagnosis still impact timely intervention critical window development inresponse 2007 american academy pedi atrics published guideline supporting need child screened asd 18 and24months age part wellchild visit myersjohnson council child disability 2007current screening typically relies caregiver reportsuch modi ed checklist asd toddler revised',\n",
              "   'asd symptom journal ofautism developmental disorder 446 1414 1424 gotham k risi pickle lord c 2007 autism diagnostic observation schedule revised algorithm forimproved diagnostic validity journal autism developmental disorder 374 613 627 s1080300602801 guha yang z grossman r b narayanan 2018 computational study expressive facial dynamic inchildren autism ieee transaction affectivecomputing 91 14 20 2578316 guha yang z ramakrishna grossman r b darren h lee narayanan 2015 quantifying facialexpressionrelated atypicality child autism spectrum disorder proceeding ieee international conferenceon acoustic speech signal processing 2015 803 807 guthrie w wallis k bennett brook e dudley j gerdes miller j 2019 accuracy autism screen ing large pediatric network pediatrics 1444e20183963 haines n bell z crowell hahn h kamara mcdonoughcaplan h beauchaine p 2019 using automated computer vision machine learning codefacial expression affect arousal implication emotion dysregulation research development'],\n",
              "  'Summaries': ['\\n \\nThe text describes a study conducted by Werner E. Dawson, J. G. Osterling, J. Dinno, and N. in 2000 that aimed to recognize Autism Spectrum Disorder (ASD) based on one-year age retrospective study using home videotapes. The study found that children with ASD had different facial expressions compared to typically developing children. In 2006, Yin L. Wei, X. Sun, J. Rosato, J. presented a facial expression database at the 7th International Conference on Automatic Face and Gesture Recognition (FGR06). The paper focused on facial behavior research and its impact on autistic, mentally retarded, and normal children. In 1989, Yirmiya, Kasari, C. Sigman, and Mundy published a study in Journal of Child Psychology and Psychiatry that explored the relationship between facial expression, affect, and autism. Additionally, Insar Carpenter et al. conducted a digital behavioral phenotyping study in 2012 that focused on Autism Spectrum Disorder (ASD).',\n",
              "   '\\n \\nThe text describes a study that used computer vision analysis (CVA) to analyze facial expressions of children with and without Autism Spectrum Disorder (ASD). The study recorded facial expressions of children using a camera and tracked facial landmarks to estimate head position and facial expression. The study found that children with ASD frequently displayed neutral expression, while children without ASD often displayed raised eyebrows and an open mouth. The study suggests that computational coding of facial movements and expression can be used to detect differences in affective expression in children with ASD. The study was published in the International Society for Autism Research journal in 2020.',\n",
              "   '\\n  The text describes a study by Yanbin et al. (2018) that explored the use of facial expression recognition technology to detect autism in children. The study included 57 items on the ABC scale, which measures facial expressions and posture, as well as the car scale, which assesses emotional responses. The researchers found that facial expression recognition technology accurately reflected the mental health of children with autism, and that changes in facial expression and posture were related to changes in emotional response. The study also demonstrated the effectiveness of using facial expression recognition technology for early diagnosis of autism.',\n",
              "   '\\n \\nThe article discusses the use of a computational assessment that records facial expressions on a tablet to detect symptoms of autism in children. The study suggests that this method could be useful for early detection, which is important for timely intervention. Despite advances in technology, the average age of autism diagnosis in the United States remains around four years old. Early detection can help identify risk signs in children as young as six months old. However, there is mixed evidence about the stability of autism traits in early childhood. The American Academy of Pediatrics published a guideline in 2007 recommending that children be screened for autism spectrum disorder (ASD) at 18 and 24 months of age during well-child visits. Current screening methods typically rely on caregiver reports, such as the ASD Toddler Revised Checklist.',\n",
              "   '\\n \\nThe text discusses various studies and research related to autism. One study focuses on improving the diagnostic validity of the Autism Diagnostic Observation Schedule (ADOS) through an algorithm revision. Another study examines the use of computational methods to analyze expressive facial dynamics in children with autism. A third study looks at quantifying facial expression-related atypicality in children with autism spectrum disorder. Additionally, a study explores the use of automated computer vision and machine learning codes to analyze facial expressions, affect arousal, and emotion dysregulation in individuals with autism.'],\n",
              "  'Result': \"\\n \\nBased on the provided information, it appears that certain facial expressions may be indicative of Autism Spectrum Disorder (ASD) in children. For example, a study published in the International Society for Autism Research journal in 2020 found that children with ASD frequently displayed neutral expression, while children without ASD often displayed raised eyebrows and an open mouth. Additionally, a study by Yanbin et al. (2018) found that changes in facial expression and posture were related to changes in emotional response in children with autism. However, it's important to note that these findings are not definitive and more research is needed to establish the specific facial expressions that can reliably detect ASD in children.\"},\n",
              " {'Question': 'What are methods to detect Autism from home videos?',\n",
              "  'Retrieved Context': ['videobased measure identify autism risk infancy gregory young phda john n constantino mdb simon dvorak bsc ashleigh belding mpha devon gangi phda alesha hill baa monique hill maa meghan miller phda chandni parikh phda aj schwichtenberg phdd erika solis bsa sally ozonoff phda adepartment psychiatry behavioral science mind institute university californiadavis bdepartment psychiatry washington universityst louis school medicine cinformation educational technology university californiadavis ddepartment human development family study purdue university abstract background sign autism present first two year life average age diagnosis lag far behind instrument improve detection autism risk infancy needed study developed tested psychometric property novel videobased approach detecting asd infancy method prospective longitudinal study child elevated lower risk autism spectrum disorder conducted participant 76 infant older sibling asd 37 infant known family history autism videoreferenced infant',\n",
              "   'research article digital behavioral phenotyping detects atypical pattern facial expression toddler autism kimberly l h carpenter jordan hahemi kathleen campbell steven j lippmann jeffrey p baker helen l egger steven espinosa saritha vermeer guillermo sapiro geraldine dawson commonly used screening tool autism spectrum disorder asd generally rely subjective caregiver questionnaire behavioral observation objective also expensive timeconsuming requires signi cant expertise perform remains critical need develop feasible scalable reliable tool characterize asd risk behavior study assessed utility tabletbased behavioral assessment eliciting detecting one type risk behavior namely pattern facial expression 104 toddler asd n 22 evaluated whether pattern differentiated toddler without asd assessment consisted child sitting hisher caregiver lap watching brief movie shown smart tablet embedded camera recorded child facial expression com puter vision analysis cva automatically detected tracked',\n",
              "   'recorded child facial expression com puter vision analysis cva automatically detected tracked facial landmark used estimate head position facial expression positive neutral using cva speci c point throughout movie identi ed reliably differentiate child without asd based pattern facial movement expression area curve individual movie ranging 062 073 instance child asd frequently displayed neutral expression compared child without asd expression frequency expression driven nonasd child often displaying raised eyebrow open mouth characteristic engagementinterest preliminary result suggest computational coding facial movement expression via tabletbased assessment detect difference affective expression one early core feature asd autism re 2020 00 1 12 2020 international society autism research wiley periodical llc lay summary study tested use tablet behavioral assessment young child autism child watched series developmentally appropriate movie facial expression recorded using camera',\n",
              "   'funding national institute health travel reimbursement andor honorarium society clinical child adolescent psychology help group dr ozonoff received research grant funding national institute health autism speaks travel reimbursement honorarium editorial activity autism speaks autism science foundation wiley book royalty guilford press american psychiatric press inc dr schwichtenberg received grant funding national institute health travel support autism speaks autism science foundation author report financial disclosure potential conflict interest abbreviation asd autism spectrum disorder virsa videoreferenced infant rating system autism reference alqabandi gorter jw rosenbaum p 2011 early autism detection ready routine screening pediatrics 1281 e211e217 pubmed 21669896 arguel jamet e 2009 using video static picture improve learning procedural content computer human behavior 25 354359 baio j wiggins l christensen dl maenner mj daniel j warren z kurziusspencer zahorodny w',\n",
              "   'disord 2016 46 6 19531961 12 fusaro va daniel j duda et al potential accelerating early detection autism content analysis youtube video plo one 2014 169 4 e93533 13 cognoa inc palo alto ca figure 5 roc curve clinical result child four year age questionnaire video based algorithm well combinatio n restricted child determined inconclusive outcome tuned 25 allowed inconclusive comparison established nonmachine learning screening tool mchat cbcl also shownjournal american medical informatics association 2018 vol 25 8 1007'],\n",
              "  'Summaries': [\"\\n \\nThe text describes a study that aimed to develop and test a new method for identifying autism risk in infancy using a video-based approach. The study was conducted as a prospective, longitudinal study with 76 participants, including infants with an elevated risk of autism spectrum disorder (ASD), infants with an older sibling with ASD, and infants with a known family history of autism. The study used videoreferencing to assess the infants' behavior and development, and evaluated the psychometric properties of the new approach. The results showed that the video-based method was able to accurately detect ASD risk in infancy, and could potentially improve the detection of ASD in the early years of life.\",\n",
              "   '\\n \\nThe research article discusses the use of digital behavioral phenotyping to detect atypical patterns in facial expressions in toddlers with autism. The study used a tablet-based behavioral assessment to evaluate the ability of computer vision analysis (CVA) to automatically detect and track facial expressions in children with autism. The results showed that CVA was able to accurately detect and differentiate between typical and atypical facial expressions in toddlers with autism, providing a feasible and scalable tool for assessing autism spectrum disorder (ASD).',\n",
              "   '\\n \\nThe text describes a study that used computer vision analysis (CVA) to analyze facial expressions of children with and without Autism Spectrum Disorder (ASD). The study recorded facial expressions of children using a camera and tracked facial landmarks to estimate head position and facial expression. The study found that children with ASD frequently displayed neutral expression, while children without ASD often displayed raised eyebrows and an open mouth. The study suggests that computational coding of facial movements and expression can be used to detect differences in affective expression in children with ASD. The study was published in the International Society for Autism Research journal in 2020.',\n",
              "   '\\n \\nThe text describes various grants and funding opportunities for researchers in the field of autism and related disorders. Dr. Ozonoff received a research grant from the National Institute of Health, while Dr. Schwichtenberg received a grant from the Autism Science Foundation. Both researchers also received travel reimbursement and honorariums for their work. Additionally, there are mentions of an editorial activity grant from Autism Speaks and a book royalty from Wiley. The text also includes references to several studies on early autism detection, including one by Argel Jamet et al. (2009) that used video and static pictures to improve learning procedures for children with autism spectrum disorder (ASD).',\n",
              "   '\\n \\nThe text describes a study published in PLOS ONE in 2014 that aimed to develop an algorithm for detecting autism at an early stage. The authors used content analysis of YouTube videos and a combination of machine learning and non-machine learning techniques to create a screening tool that was able to accurately identify children with autism. The study found that the tool was effective in identifying children with autism, even those who were not yet diagnosed. The authors also compared their results with other screening tools, including MCHAT and CBCL, and found that their approach was more accurate than these traditional methods. The study was published in the Journal of American Medical Informatics Association in 2018.'],\n",
              "  'Result': \"\\n \\nThere are several methods to detect autism from home videos. One such method is a video-based approach that uses videoreferencing to assess an infant's behavior and development. This approach has been shown to accurately detect autism risk in infancy and could potentially improve the detection of autism in the early years of life. Another method is digital behavioral phenotyping, which uses computer vision analysis (CVA) to automatically detect and track facial expressions in children with autism. This method has been shown to accurately detect and differentiate between typical and atypical facial expressions in toddlers with autism, providing a feasible and scalable tool for assessing autism spectrum disorder (ASD). Additionally, computer vision analysis (CVA) can be used to analyze facial expressions of children with and without ASD to detect differences in affective expression.\"},\n",
              " {'Question': 'What is Still-Face Paradigm in Early Screening for High-Risk Autism Spectrum Disorder?',\n",
              "  'Retrieved Context': ['child watched series developmentally appropriate movie facial expression recorded using camera embedded tablet result suggest computational assessment facial expression may useful early detec tion symptom autism keywords autism risk behavior facial expression computer vision early detection introduction autism spectrum disorder asd reliably diagnosed early 24 month old risk sign detected early 6 12 month old dawson bernier 2013 luyster et al 2009 despite aver age age diagnosis united state remains around 4 year age christensen et al 2016 mixed evidence stability autism trait early childhood bieleninik et al 2017 waizbardbartov et al 2020 delay diagnosis still impact timely intervention critical window development inresponse 2007 american academy pedi atrics published guideline supporting need child screened asd 18 and24months age part wellchild visit myersjohnson council child disability 2007current screening typically relies caregiver reportsuch modi ed checklist asd toddler revised',\n",
              "   'face scanning typical atypical development soc cogn affect neurosci 95 3 8543 2014 4 0 j n e w k l n e n nt oe e present decline 26month old infant later diagnosed autism nature 5044 2 7431 2013 4 1 p u l r f u e r r g c h w r k k k l n u ft h em u h f babe vocal production infan sibling child asd j child psychol psychiatry 525 8 8598 2011 4 2 h e n k p f j v e r n j r n l l l e e r b p c lc r ya c u c 6monthold infant risk autism spectrum disorder autism re 5 331339 2012ouss et al translational psychiatry 2020 1054 page 7 7',\n",
              "   'disord 2016 46 6 19531961 12 fusaro va daniel j duda et al potential accelerating early detection autism content analysis youtube video plo one 2014 169 4 e93533 13 cognoa inc palo alto ca figure 5 roc curve clinical result child four year age questionnaire video based algorithm well combinatio n restricted child determined inconclusive outcome tuned 25 allowed inconclusive comparison established nonmachine learning screening tool mchat cbcl also shownjournal american medical informatics association 2018 vol 25 8 1007',\n",
              "   'vermont research center child youth family 2001 6 lord c rutter le couteur autism diagnostic interviewrevised revised version diagnostic interview caregiver individual possible pervasive developmental disorder j autism dev disord 1994 24 5 65985 7 lord c rutter goode et al autism diagnostic observation schedule standardized observation communicative social behavior j au tism dev disord 1989 19 2 185212 8 lord c petkova e hus v et al multisite study clinical diagnosis different autism spectrum disorder arch gen psychiatry 2012 69 3 30613 9 wall dp dally r luyster r et al use articial intelligence shorten behavioral diagnosis autism plo one 2012 7 8 e43855 10 duda kosmicki ja wall dp et al testing accuracy observationbased classier rapid detection autism risk transl psy chiatry 2014 4 8 e424 11 dudadaniels mj wall dp clinical evaluation novel mobile au tism risk assessment j autism dev disord 2016 46 6 19531961 12 fusaro va daniel j duda et al potential accelerating early detection',\n",
              "   'k estes webb 2016 reduced engagement social stimulus in6monthold infant later autism spectrum disorder alongitudinal prospective study infant high familial riskjournal neurodevelopmental disorder 81 7 khowaja robin l adamson l b 2017 utilizing twotiered screening early detection autism spectrumdisorder autism 22 881 890 1362361317712649 lewinski p 2015 automated facial coding software outper form people recognizing neutral face neutral fromstandardized datasets frontier psychology 6 1386lobue v thrasher c 2014 child affective facial expression cafe set validity reliability untrainedadults frontier psychology 5 1532 lord c risi lambrecht l cook e h jr leventhal b l dilavore p c rutter 2000 autism diagnostic observation schedulegeneric standard measure socialand communication de cits associated spectrum autism journal autism developmental disorder 303 205 223 lord c rutter le couteur 1994 autism diagnostic interviewrevised revised version diagnostic interviewfor caregiver individual'],\n",
              "  'Summaries': ['\\n \\nThe article discusses the use of a computational assessment that records facial expressions on a tablet to detect symptoms of autism in children. The study suggests that this method could be useful for early detection, which is important for timely intervention. Despite advances in technology, the average age of autism diagnosis in the United States remains around four years old. Early detection can help identify risk signs in children as young as six months old. However, there is mixed evidence about the stability of autism traits in early childhood. The American Academy of Pediatrics published a guideline in 2007 recommending that children be screened for autism spectrum disorder (ASD) at 18 and 24 months of age during well-child visits. Current screening methods typically rely on caregiver reports, such as the ASD Toddler Revised Checklist.',\n",
              "   '\\n \\nThe text discusses various research studies related to face scanning, typical and atypical development, social cognition, affective neuroscience, and autism. One study found that a 26-month-old infant who was later diagnosed with autism had a decline in neural connectivity in certain regions of the brain related to vocal production and social interaction. Another study found that siblings of children with autism spectrum disorders (ASD) were also at risk for developing ASD. Translational psychiatry researchers have also been studying the relationship between autism and neural connectivity in the brain.',\n",
              "   '\\n \\nThe text describes a study published in PLOS ONE in 2014 that aimed to develop an algorithm for detecting autism at an early stage. The authors used content analysis of YouTube videos and a combination of machine learning and non-machine learning techniques to create a screening tool that was able to accurately identify children with autism. The study found that the tool was effective in identifying children with autism, even those who were not yet diagnosed. The authors also compared their results with other screening tools, including MCHAT and CBCL, and found that their approach was more accurate than these traditional methods. The study was published in the Journal of American Medical Informatics Association in 2018.',\n",
              "   '\\n \\nThe text discusses various studies and research related to autism spectrum disorders (ASD). The first study, conducted in 2001 by Lord, C. R., LeCouteur, A., Autism Diagnostic Interview Revised (ADIR), is a diagnostic tool used for identifying individuals with ASD. The second study, conducted in 1994 by Lord, C. R., Goode, E., Autism Diagnostic Observation Schedule (ADOS), is a standardized observation tool used to assess communicative, social, and behavioral aspects of individuals with ASD. The third study, conducted in 2012 by Wall, D. L., Dally, R., Luyster, R. E., et al., uses artificial intelligence to shorten the behavioral diagnosis process for individuals with ASD. The fourth study, conducted in 2014 by Duda, K., Kosmicki, J., Wall, D. L., et al., focuses on testing accuracy and observation-based classification for rapid detection of autism risk. The fifth study, conducted in 2016 by Fusaro, V., Daniel, J., Duda, K., et al., explores the potential for accelerating early detection of ASD using mobile assessment tools.',\n",
              "   '\\n \\nThe text describes a longitudinal prospective study conducted by Kestes et al. (2016) that found reduced engagement with social stimuli in infants at six months old, which was later associated with an increased risk of autism spectrum disorder (ASD). The study utilized a two-tiered screening approach for early detection and diagnosis of ASD. Additionally, Lewinski et al. (2015) developed an automated facial coding software that outperformed humans in recognizing neutral faces from standardized datasets. Finally, Lord et al. (2000) developed an autism diagnostic observation schedule, which is a generic standard measure used to assess social and communication symptoms associated with ASD.'],\n",
              "  'Result': \"\\n \\nThe Still-Face Paradigm is a technique used in early screening for high-risk autism spectrum disorder (ASD). It involves presenting a child with a still face, or a neutral expression, while observing their response. The idea behind this paradigm is that children with ASD may struggle to recognize and respond appropriately to social cues, such as a still face.\\n\\nResearch has shown that children with ASD tend to have difficulty interpreting social cues, including facial expressions. In the Still-Face Paradigm, the child is presented with a still face and asked to interact with it. If the child does not respond appropriately, this could indicate a deficit in social cognition, which is a common symptom of ASD.\\n\\nThe Still-Face Paradigm has been used in several studies to screen for ASD in infants and young children. For example, a study by Kestes et al. (2016) found that infants at six months old who showed reduced engagement with a still face were at increased risk for developing ASD.\\n\\nOverall, the Still-Face Paradigm is a valuable tool in early screening for ASD, as it allows researchers to assess a child's ability to interpret social cues and identify potential deficits in social cognition.\"},\n",
              " {'Question': 'What is West Syndrome?',\n",
              "  'Retrieved Context': ['l ruta l gangemi pioggia g autism social robotics systematic review 2016 5 american psychiatric association dsm5 diagnostic classifica tion diagnostic statistical manual mental disorder american psychiatric association 5 2013 6 eggebrecht elison jt feczko e todorov wolff jj kandala adam cm snyder az lewis jd estes zwaigenbaum l botteron kn mckinstry rc constantino jn evans hazlett hc dager paterson sj schultz rt styner gerig g da kostopoulos p schlaggar bl petersen se piven j pruett jr joint attention brain functional connectivity infant toddler cerebral cortex 273 17091720 2017 7 steiner goldsmith tr snow av chawarska k disorder infant toddler j autism dev disord 426 11831196 2012 8 belpaeme baxter pe read r wood r cuay ahuitl h kiefer b racioppa kruijffkorbayov athanasopoulos g enescu v looije r neerincx demiris ro espinoza r beck canamero l hiolle lewis baroni nalin cosi p paci g tesser f sommavilla g humbert r multimodal childrobot interaction building social bond journal',\n",
              "   'ouss et al translational psychiatry 2020 1054 article open access behavior interaction imaging 9 month age predict autismintellectual disability highriskinfants west syndrome lisa ouss1g u e p p ep l e r a2 catherine saintgeorges23 marluce leitgel gille1 mohamed afshar4 hugues pellerin2 kevin bailly2 mohamed chetouani2 laurence robel1b e r n r dg l e1 rima nabbout5 isabelle desguerre5 mariana guergovakuras4and david cohen23 abstract automated behavior analysis promising tool overcome current assessment limitation psychiatry 9 month age recorded 32 infant west syndrome w 19 typically developing td control astandardized mother infant interaction computed infant hand movement hm speech turn taking partner vocalization pause silence overlap motherese assessed whether multimodal social signal interactional synchrony 9 month could predict outcome autism spectrum disorder asd intellectualdisability id infant w 4 year followup 10 infant developed asdid w best machine learning reached 7647',\n",
              "   'age 2625 953a3814 497b3954 460b msel outcome receptive language age eq 2560 955a3566 568b3751 478b note value different subscript significantly different p05 social affect restrictive repetitive behavior overall total msel outcome mullen scale early learning 36 month age j child psychol psychiatry author manuscript available pmc 2021 january 01author manuscript author manuscript author manuscript author manuscriptyoung et al page 14 table 2 roc analysis 36month asd diagnostic classification 6 month 9 month 12 month 18 month true positive 7 10 8 14 false positive 11 37 31 31 true negative 36 29 51 35 false negative 6 6 8 4 auc 62 42 59 71 specificity 95 ci 77 65 89 44 32 56 62 52 73 53 41 65 sensitivity 95 ci 54 26 81 63 39 86 50 26 75 78 59 97 negative predictive value 95 ci 86 75 96 83 70 95 86 78 95 90 80 99 positive predictive value 95 ci 39 16 61 21 10 33 21 08 33 31 18 45 threshold 525 825 675 825 j child psychol psychiatry author manuscript available pmc 2021 january 01author',\n",
              "   'webbased screening asd development virsa lowburden quick online rating potential reduce disparity community limited access screening provide possibility initiating intervention full symptom set asd emerged supplementary material refer web version pubmed central supplementary materialyoung et al page 7 j child psychol psychiatry author manuscript available pmc 2021 january 01 author manuscript author manuscript author manuscript author manuscriptacknowledgments work supported nih grant r01 mh099046 ozonoff u54 hd079125 abbeduto mind institute intellectual developmental disability research center autism speaks grant 8370 ozonoff deeply grateful parent authorized use child video development virsa child family participated validation study disclosure dr constantino receives royalty western psychological service commercial distribution social responsiveness scale dr miller received research grant funding national institute health travel reimbursement andor honorarium society clinical child',\n",
              "   'literature review eur child adolesc psychiatry 2013 22 329340 crossref pubmed 6 bailey le couteur gottesman bolton p simono e yuzda e rutter autism strongly genetic disorder evidence british twin study physiol med 1995 25 6377 crossref pubmed 7 du fh al h stable pattern eeg spectral coherence distinguishes child autism neurotypical controlsa large case control study bmc med 2012 10 64 crossref pubmed 8 chaspari lee cc narayanan s interplay verbal response latency physiology child autism eca interaction proceeding annual conference international speech communication association interspeech portland usa 913 september 2012 pp 13191322 9 baroncohen social pragmatic decits autism cognitive ective j autism dev disord 1988 18 379402 crossref pubmed 10 bonneh y levanon deanpardo lossos l adini abnormal speech spectrum increased pitch variability young autistic child front hum neurosci 2011 4 237 crossref pubmed 11 chericoni n de brito wanderley costanzo v dinizgonalves gille ml parlato e'],\n",
              "  'Summaries': ['\\n \\nThe text describes a systematic review of research on the use of social robots in the treatment of autism and other developmental disorders. The study was conducted by a team of researchers from various institutions, including the American Psychiatric Association, and used the Diagnostic and Statistical Manual (DSM) as a framework for classification. The review found that social robots have shown promise in improving communication and social skills in children with autism and other developmental disorders, but more research is needed to fully understand their effectiveness. The study also explored the neural mechanisms underlying the use of social robots in this context, using techniques such as joint attention and brain functional connectivity. Overall, the review highlights the potential benefits of social robotics in the treatment of developmental disorders, and suggests that further research is necessary to fully realize these benefits.',\n",
              "   '\\n \\nThe study by Ouss et al. (2020) aimed to investigate the use of behavior interaction imaging and automated behavior analysis as a promising tool for predicting autism spectrum disorder (ASD) and intellectual disability (ID) in infants at 9 months old. The study involved recording the behavior of 32 infants, including those with West syndrome and typically developing controls, using standardized mother-infant interaction and computing their hand movements, speech, turn-taking, partner vocalization, pause, silence, and overlap. The researchers assessed multimodal social signal interactional synchrony at 9 months old to predict the outcome of ASD and ID at a 4-year follow-up. The results showed that the best machine learning model reached an accuracy of 76.47% in predicting the development of ASD and ID in infants at 9 months old.',\n",
              "   '\\n \\nThe article discusses the use of a machine learning algorithm to predict autism spectrum disorder (ASD) in children at 36 months old. The algorithm used a Mullen Scale of Early Learning and was trained on data from 1,000 children with ASD and 1,000 typically developing children. The algorithm achieved an area under the curve (AUC) of 62, with a specificity of 77% and a sensitivity of 54%. The authors also reported that the algorithm had a negative predictive value of 86%, meaning that it correctly identified children who did not have ASD. The threshold for classifying a child as having ASD was set at a score of 525 on the Mullen Scale. Overall, the study suggests that machine learning algorithms can be effective in predicting ASD in young children.',\n",
              "   '\\n \\nThe article discusses a web-based screening tool for Autism Spectrum Disorder (ASD) that was developed by Young et al. The tool, called Virsa, is designed to be quick, easy to use, and accessible online. It has the potential to reduce disparities in access to ASD screening within communities. The authors acknowledge support from various grants, including an NIH grant and an Autism Speaks grant. They also thank parents who authorized the use of child videos for validation purposes and disclose potential conflicts of interest.',\n",
              "   \"\\n \\nThe literature review in the journal Eur Child Adolescent Psychiatry in 2013 discusses various aspects of autism, including its genetic basis and the use of electroencephalography (EEG) to distinguish between autistic children and neurotypical controls. The study found that EEG spectral coherence can be used to differentiate between autistic children and neurotypical controls. Additionally, the study examined the interplay between verbal response latency and physiological measures in autistic children. Another study was also discussed, which found an increased pitch variability in young autistic children's frontal cortex activity. Finally, the article mentions a study on social pragmatic deficits in autism, which is a cognitive and executive function domain.\"],\n",
              "  'Result': '\\n \\nWest Syndrome is a rare genetic disorder that affects the nervous system and causes developmental delays, seizures, and other neurological symptoms. It is characterized by triad of symptoms: delayed language development, delayed motor development, and delayed social development. Children with West Syndrome may also experience muscle stiffness, spasticity, and abnormal movements. The condition is caused by mutations in the gene that codes for a protein called myelin protein phosphatase receptor (MPPR), which plays a role in the formation and maintenance of myelin sheaths around nerve cells. There is no cure for West Syndrome, and treatment typically involves managing symptoms through medication, physical therapy, and other interventions.'},\n",
              " {'Question': 'What is the utility of Behavior and interaction imaging at 9 months of age predict autism/intellectual disability in high-risk infants with West syndrome?',\n",
              "  'Retrieved Context': ['ouss et al translational psychiatry 2020 1054 article open access behavior interaction imaging 9 month age predict autismintellectual disability highriskinfants west syndrome lisa ouss1g u e p p ep l e r a2 catherine saintgeorges23 marluce leitgel gille1 mohamed afshar4 hugues pellerin2 kevin bailly2 mohamed chetouani2 laurence robel1b e r n r dg l e1 rima nabbout5 isabelle desguerre5 mariana guergovakuras4and david cohen23 abstract automated behavior analysis promising tool overcome current assessment limitation psychiatry 9 month age recorded 32 infant west syndrome w 19 typically developing td control astandardized mother infant interaction computed infant hand movement hm speech turn taking partner vocalization pause silence overlap motherese assessed whether multimodal social signal interactional synchrony 9 month could predict outcome autism spectrum disorder asd intellectualdisability id infant w 4 year followup 10 infant developed asdid w best machine learning reached 7647',\n",
              "   '7 4 3 1759 2009 10 jaffe j beebe b feldstein crown c l jasnow rhythm dialogue infancy coordina ted timing development monogr soc re child dev 661132 2001 11 cohen et al parentese prosody father involvement interacting facilitate social interaction fants later develop autism plo one 8 e61402 2013 12 hammal z cohn j f messinger head movement dynamic play perturbed motherinfant interaction ieee trans affect comput 6 361370 2015 13 ouss l et al developmental trajectory hand movement typical infant risk developmental disorder observational study ofkinematics rst year life front psychol 98 3 2 0 1 8 14 ouss l et al taking account infant engagement emotion early interaction may help determine risk autism intellectual disability infant west syndrome eur child adolesc psychiatry 23 143149 2014 15 josse le manuel blrc brunetlzine rvis echelle de developpement psychomoteur de la premiere enfance eap paris 1997 16 lord c rutter le couteur autism diagnostic interviewrevised revised version',\n",
              "   'j dickinson h lord c early indicator autism spectrum disorder second year lif ej autism devdisord 20043447393doi101007s108030042544y 8 barbaro j dissanayake c early marker autism spectrum disorder infant toddler prospectively identied social attention communication study autism 2013 176486 doi1011771362361312442597 9 zwaigenbaum l bauman ml stone wl yirmiya n estes hansen rl et al early identication autism spectrum disorder recommendati ons practice research pediatrics 2015 4892102 136suppl 1s1040 doi101542peds20143667c 10 cassel td messinger d ibanez lv haltigan jd acosta si buchman ac early social emotional communication infant sibling child frontier pediatrics wwwfrontiersinorg 8 june 2020 volume 8 article 290qiu et al early screening highrisk asd autism spectrum disorder examination broad phenot ypej autismdevdisord 20073712232doi101007s1080300603371 11 heimann laberg ke norden b imitative interaction increas e social interestandelicitedimitationinnonverbalchildrenwithauti',\n",
              "   'distin guish w versus td probably ecting motor impact due acute w encephalopathy classifying wsvs w contribution infant audio feature synchrony feature became much relevantcombined several hm feature believe importance synchrony reciprocity early interaction line withrecent study investigated risk asd orndd rst year life home movie eg ref 1124 prospective followup highrisk n f n s u c ha s b l n g e g r e f 428 infant w eg ref14 prospective study assessing tool screen risk autism eg ref29 eld asd synchrony reciprocity parental sensitivity emotional engagement proposed target ofearly intervention 30 could prevent early inter active vicious circl e parent atrisk infant try compensate lack interactivity child modifying stimulation therefore sometimesreinforcing dysfunctional interaction 24e r l identi cation interactive target especially useful among baby neurological comorbiditiesbecause delay developmental milestone andimpairments early social interaction suf cient predict asd',\n",
              "   'literature review eur child adolesc psychiatry 2013 22 329340 crossref pubmed 6 bailey le couteur gottesman bolton p simono e yuzda e rutter autism strongly genetic disorder evidence british twin study physiol med 1995 25 6377 crossref pubmed 7 du fh al h stable pattern eeg spectral coherence distinguishes child autism neurotypical controlsa large case control study bmc med 2012 10 64 crossref pubmed 8 chaspari lee cc narayanan s interplay verbal response latency physiology child autism eca interaction proceeding annual conference international speech communication association interspeech portland usa 913 september 2012 pp 13191322 9 baroncohen social pragmatic decits autism cognitive ective j autism dev disord 1988 18 379402 crossref pubmed 10 bonneh y levanon deanpardo lossos l adini abnormal speech spectrum increased pitch variability young autistic child front hum neurosci 2011 4 237 crossref pubmed 11 chericoni n de brito wanderley costanzo v dinizgonalves gille ml parlato e'],\n",
              "  'Summaries': ['\\n \\nThe study by Ouss et al. (2020) aimed to investigate the use of behavior interaction imaging and automated behavior analysis as a promising tool for predicting autism spectrum disorder (ASD) and intellectual disability (ID) in infants at 9 months old. The study involved recording the behavior of 32 infants, including those with West syndrome and typically developing controls, using standardized mother-infant interaction and computing their hand movements, speech, turn-taking, partner vocalization, pause, silence, and overlap. The researchers assessed multimodal social signal interactional synchrony at 9 months old to predict the outcome of ASD and ID at a 4-year follow-up. The results showed that the best machine learning model reached an accuracy of 76.47% in predicting the development of ASD and ID in infants at 9 months old.',\n",
              "   \"\\n \\nThe text describes a research article that explores the relationship between early childhood development and the risk of developing autism, intellectual disability, and other developmental disorders. The article discusses various factors that can influence this risk, such as infant engagement, emotion, and early interaction with caregivers. It also examines the role of observation in determining risk and highlights the importance of taking into account the child's emotional state during interactions. The article suggests that understanding these factors could help identify children at risk for these conditions earlier, allowing for more effective interventions.\",\n",
              "   '\\n \\nThe text discusses various studies and research related to early identification of Autism Spectrum Disorder (ASD) in infants, toddlers, and children. The authors recommend practices for early identification and emphasize the importance of social attention, communication, and imitative interaction in identifying ASD. Some studies have used examinations and broad phenotype assessments to screen for ASD, while others have focused on nonverbal children with ASD. Overall, the text highlights the need for continued research and practice in the field of early identification of ASD.',\n",
              "   '\\n \\nThe text discusses the importance of synchrony in early interactions between parents and infants, particularly for children with autism spectrum disorder (ASD). Synchrony refers to the coordination of movements and behaviors between individuals, and it is believed to play a crucial role in the development of social skills and communication. Recent studies have shown that synchrony is particularly important for infants with ASD, as it can help them develop their social and emotional skills. Early intervention programs that focus on promoting synchrony and improving parent-child interaction may be effective in preventing the development of ASD and other neurodevelopmental disorders.',\n",
              "   \"\\n \\nThe literature review in the journal Eur Child Adolescent Psychiatry in 2013 discusses various aspects of autism, including its genetic basis and the use of electroencephalography (EEG) to distinguish between autistic children and neurotypical controls. The study found that EEG spectral coherence can be used to differentiate between autistic children and neurotypical controls. Additionally, the study examined the interplay between verbal response latency and physiological measures in autistic children. Another study was also discussed, which found an increased pitch variability in young autistic children's frontal cortex activity. Finally, the article mentions a study on social pragmatic deficits in autism, which is a cognitive and executive function domain.\"],\n",
              "  'Result': \"\\n \\nBased on the research findings, behavior and interaction imaging at 9 months of age has shown promise in predicting autism and intellectual disability in high-risk infants with West syndrome. The study by Ouss et al. (2020) recorded the behavior of 32 infants, including those with West syndrome and typically developing controls, using standardized mother-infant interaction and computed their hand movements, speech, turn-taking, partner vocalization, pause, silence, and overlap. The researchers assessed multimodal social signal interactional synchrony at 9 months old to predict the outcome of ASD and ID at a 4-year follow-up. The results showed that the best machine learning model reached an accuracy of 76.47% in predicting the development of ASD and ID in infants at 9 months old. This suggests that behavior and interaction imaging at 9 months of age can provide valuable information about an infant's risk for autism and intellectual disability, potentially allowing for earlier interventions and better outcomes.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCaZuIPn_pSL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}